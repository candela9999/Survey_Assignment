---
title: "Survey II Assignment"
author: "..."
output: 
  html_document:
    toc: true
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Loading libraries

```{r, message = FALSE, warning=FALSE}
rm(list = ls())
library(MASS)
library(tidyverse)
library(haven)
library(readxl)
library(xml2)
library(rvest)
library(janitor)
library(DataExplorer)
library(countrycode)
library(explore)
library(lme4)
library(lmerTest)
library(broom.mixed)
library(ggplot2)
library(dplyr)
library(scales)
library(tidyr)
library(kableExtra)
library(gmodels)
library(flexplot)
library(corrplot)
library(caret)
library(ROSE)
library(randomForest)
library(pROC)
library(mice)
```

# Loading data

## Survey data

```{r}
data_raw <- read_dta("ZA7575.dta")
```

## Country-level data

This is for joins:

```{r, message=FALSE}
# building a df with country names and codes for the EU-28
codelist <- countrycode::codelist |> 
  select(country.name.en, iso.name.en, un.name.en, cow.name, ecb, eurostat, iso2c, iso3c, eu28) |> 
  filter(!is.na(eu28)) 
```

### GDP per capita, PPP (constant 2021 international \$)

Retrieved from the World Bank
(<https://data.worldbank.org/indicator/NY.GDP.PCAP.PP.KD>) for the year
2019.

```{r}
gdp_data <- read_csv("gdp_pc_ppp_2021.csv", skip = 4)

head(gdp_data)

gdp_data <- gdp_data |> 
  select(`Country Name`, `Country Code`, `2019`)


gdp_data <- gdp_data |> 
  rename(country_name = `Country Name`,
         country_code = `Country Code`,
         gdp_pc_ppp = `2019`)

gdp_data <- gdp_data |> 
inner_join(select(codelist, iso3c), by = c("country_code" = "iso3c"))

str(gdp_data)
```

We now have 28 observations including the UK.

### Rural population

Retrieved from the World Bank
(<https://data.worldbank.org/indicator/SP.RUR.TOTL.ZS>).

Data on the % of population living in rural areas over total population.

```{r}
rural_data <- read_xls("rural_pop.xls", sheet = 1, range = "A4:BL270")
head(rural_data)

# selecting only the relevant year
rural_data <- rural_data |> 
  select(`Country Name`, `Country Code`, `2019`) |> 
  clean_names() |> 
  rename("rural_pop_percentage" = "x2019")

rural_data <- rural_data |> 
  inner_join(select(codelist, iso3c), by = c("country_code" = "iso3c"))

str(rural_data)
```

### Same sex unions

Retrieved from Wikipedia
(<https://en.wikipedia.org/wiki/Recognition_of_same-sex_unions_in_Europe>).

Table about status of same sex unions by country in Europe.

```{r}
# scraping the table
marriage_data <- read_html("https://en.wikipedia.org/wiki/Recognition_of_same-sex_unions_in_Europe") |>
  html_table() %>%
  .[[4]] |>
  select(Status, Country)

# cleaning the status column
marriage_data <- marriage_data |> 
  mutate(Status = str_remove(Status, "\\s*\\(.*|\\s*-.*")) |> 
  filter(!Status %in% c("Total", "Subtotal"))

# cleaning the country column
marriage_data <- marriage_data |> 
  mutate(Country = str_replace_all(Country, c("\\*" = "", "†" = "", "\\[.*?\\]" = ""))) |> 
  mutate(Country = trimws(Country))

# keeping only eu-28 countries 
marriage_data <- marriage_data |> 
  inner_join(select(codelist, cow.name), by = c("Country" = "cow.name"))

str(marriage_data)
```

This variable could be recoded as either ordinal, categorical (both
factor) or logical.

The dataset has 32 observations instead of 28 (EU-28 countries).

```{r}
marriage_data |> 
  add_count(Country) |> 
  filter(n > 1)
```

According to this test, Croatia, Hungary, Latvia and Slovakia have two
different types of status, so maybe we should cross-check with other
sources?

Diego: the thing is that countries can at the same time have a
constitutional ban on marriage and still have legally recognized civil
unions. Thus maybe we should exclude this level from this variable as it
is not exclusive. The lowest level would remain no recognition.

Irene: I guess we need to decide whether we think it is more
important/representative of a country to have civil unions for same-sex
couples or a constitutional ban on same-sex marriage (this feels pretty
strong tbh). It depends also on how we want to recode this.

<br>

The table is up to date, so I had to check (on Wikipedia honestly) what
year each of those items was actually legalized and I got to this:

-----------------------------same sex
marriage-----------------------------

Greece: civil unions since 2015, marriage since 2024

Estonia: civil unions since 2016, marriage since 2024

Slovenia: civil unions since 2017, marriage since 2022

United Kingdom: marriage since 2014 in England, Scotland and Wales, and
since 2020 in Northern Ireland. Civil unions since 2005

---------------------------------civil
unions-----------------------------------

Latvia: civil unions since 2024, the Constitution prohibits the
recognition of same sex marriage since 2006.

```{r}
marriage_data <- marriage_data |> 
  mutate(Status = case_when(
    Country == "Greece" ~ "Civil Unions",
    Country == "Estonia" ~ "Civil Unions",
    Country == "Slovenia" ~ "Civil Unions",
    Country == "United Kingdom" ~ "Civil Unions" ,  # I understand that same-sex marriage wasn't legal in the UK until it was legalised in all of its territories, but this can be discussed
    Country == "Latvia" & Status == "Civil unions" ~ "No recognition", # only mutate one of the rows that Latvia is in
    # Latvia had no recognition prior to 2024, but it has a constitutional ban on marriage, which is a category that we found alongside others in some observations, so we'll keep two rows for Latvia for now
    TRUE ~ Status
  ))

marriage_data |> filter(Country %in% c("Latvia", "Greece", "Estonia", "Slovenia", "United Kingdom"))
```

I also found this LGBT rights index on Our World in Data
(<https://ourworldindata.org/grapher/lgbt-rights-index>) which captures
whether LGBT+ people enjoy the same rights as cisgender people combining
information on 18 different policies. It includes the legal status of
same-sex marriage so we might keep only one of these.

```{r}
lgbt_rights_index <- read.csv("lgbt-rights-index.csv")

lgbt_rights_index <- lgbt_rights_index |> 
  filter(Year == 2019) |> 
  inner_join(select(codelist, iso3c), by = c("Code" = "iso3c")) |> 
  select(-Year) # all observations are from 2019

str(lgbt_rights_index)
```

Column names can be renamed:

```{r}
lgbt_rights_index <- lgbt_rights_index |> 
  rename(country_name = Entity,
         country_code = Code,
         lgbt_policy_index = LGBT..Policy.Index) 
```

### Gender inequality index

Gender Development and Gender Inequality indexes, developed by the
United Nations Development. Retrieved from
<https://hdr.undp.org/data-center/documentation-and-downloads> for the
year 2019.

```{r}
gender_index <- read_xlsx("UNDP_gender_indexes.xlsx")

gender_index <- gender_index |>
  select(-dimension, -note, -year) |> # empty/useless columns
  inner_join(select(codelist, iso3c), by = c("countryIsoCode" = "iso3c"))

gender_index |> 
  distinct(country) |> 
  nrow()

str(gender_index)
```

We checked that we have indeed 28 distinct countries in the dataset.

This dataset collects many indicators apart from the indexes values. We
are selecting only the Gender Development and Gender Inequality indexes
(GDI and GII):

```{r}
gender_index <- gender_index |> 
  filter(indicatorCode %in% c("gdi", "gii")) |> 
  select(-c(indexCode, indicatorCode, indicator)) |> # removing redundant columns
  pivot_wider(names_from = index, values_from = value)

colnames(gender_index) <- janitor::make_clean_names(colnames(gender_index)) # cleaning spaces and upper cases
```

And then exploring them to see which one is a better fit for modeling
and predictions:

```{r}
summary(gender_index$gender_inequality_index)
summary(gender_index$gender_development_index)

sd(gender_index$gender_inequality_index)
sd(gender_index$gender_development_index)
```

We observe that the second one (Gender Development Index) has a very
small range, indicating that most countries have nearly identical
scores. This is supported by the standard deviation, which shows that
the GII is more spread out than the GDI. Being almost constant, GDI
won’t add much value to the analysis. This is likely due to the fact
that these indexes are created by the United Nations Development
Programme for all countries, so it may not capture the finer differences
between EU countries.

```{r}
cor(gender_index$gender_inequality_index, 
    gender_index$gender_development_index, 
    use = "complete.obs")
```

Surprisingly, the two indexes have a very weak positive correlation.
While they are not inverse, I was expecting them to measure opposite
things, so maybe the correlation coefficient is not useful here because
of the low variation of both variables (specially GDI). I don't know
what else to do with this info other than keeping GII and discarding
GDI.

```{r}
gender_index <- gender_index |> 
  select(-gender_development_index)
```

### Economist's Democracy Index

```{r}
democracy_index <- read_xlsx("EIU_democracy_index.xlsx", sheet = 4)

# the ISO codes were lowercase which impedes the join
democracy_index$geo <- toupper(democracy_index$geo)

# filter for 2019 and EU28 countries
democracy_index <- democracy_index |> 
  filter(time == 2019) |> 
  inner_join((select(codelist, iso3c)), by = c("geo" = "iso3c"))

# clean var names
names(democracy_index) <- names(democracy_index) %>%
  janitor::make_clean_names() %>%
  gsub("_eiu$", "", .)

democracy_index <- democracy_index |> 
  rename(country_code = geo,
         country_name = name,
         year = time)

str(democracy_index)
```

In this case, we are only keeping the

```{r}
democracy_index <- democracy_index |> 
  select(country_name, country_code, democracy_index)
```

# Data cleaning

## Selecting relevant variables in the survey data

We are discarding all variables that relate to trade and globalization
as deemed not relevant for our analysis `qa`. We are also discarding
variables related to energy policies `qb`.

We have also not considered questions specifically about Roma ex `qc8`
and `qc14` and `qc16`

<br>

Some of the doubts we had:

AGE

```{r}
x_df <- data_raw |> summarise(mean = mean(qc19), .by = d11)
ggplot(x_df, aes(x = d11, y = mean)) + geom_point()
```

As relationship seems pretty linear we are going to use the continuous
variable for age and there seems to be a clear group (1to4) which is the
same used in the variable with 3 categories left, center and right so we
will use the 3-categories variable

<br>

POLITICAL OPINIONS

```{r}
x_df <- data_raw |> summarise(mean = mean(qc19), .by = d1)
ggplot(x_df, aes(x = d1, y = mean)) + geom_point() + xlim(1,10)
```

For political opinions it seems that the relationship is less linear so
we will work on the 5 categories cod

<br>

MARRIAGE

```{r}
x_df <- data_raw |> summarise(mean = mean(qc19), .by = d7r1)
ggplot(x_df, aes(x = d7r1, y = mean)) + geom_point() + xlim(1,5)
```

Of all the possible combinations this one seems the best to highlight
differences in our target variable

<br>

NATIONALITY

There is no easy way to create an immigrant dummy by checking whether
someone does not have the nationality of the country in which he is
being interviewed for the survey. So we are just going to use `q1_29` as
a dummy for whether someone owns a non-EU nationality

<br>

POLITICAL INTEREST

Using only `polintr` as a summary of the whole `d71` question about how
strong is your interest in politics in various domains

<br>

EXPERIENCED DISCRIMINATION

For the questions about whether you have experienced discrimination
`qc2_` I am keeping only `qc2_15` which is a binary on whether you have
experienced any discrimination or not and I am not keeping the other
categories that allowed us to understand if you had experienced
discrimination on the basis of a particular motive. We can probably
assume that if a person is a part of a specific minority (info from
`sd2`) and is being discriminated is because of being part of that
minority (at least in most cases), therefore it felt like information we
already had (and which we can easily put in our regression using
interaction effects)

<br>

PERCIEVED DISCRIMINATION in country

This is a question (`qc1`) about how widespread you perceived
discrimination is in your country. It is a rather peculiar question
because it asks individUals for perception at the country level. I think
it might be more useful (by aggregating results by country) to use it to
build a country level indicator of perceived discrimination against
certain minorities that are of our interest rather than use it as an
individual level variable. So I will keep them out of the dataset for
now

For the same reason I am also discarding `qc4` that asks whether in your
country you feel like candidates with certain characteristics would be
at a disadvantage in the recruitment process. It still basically asks
about perceived discrimination at the country level.

And the same reasoning also applies to `qc7` which asks if efforts
towards reducing discrimination are effective in your country.

<br>

HOW DISCRIMINATORY ARE YOU score

I use `qc12` and `qc13` to build a score from 1 to 10 of how
discriminatory are you against certain minorities. I am building the
score for each minority and then we can decide later if some are
irrelevant.

Note for some categories this score is a bit stupid (ex. voting for
whether you would feel uncomfortable if your child was in a love
relationship with a old person would give you a high racist score
against old people, this is an example of some of the categories for
which it is worth excluding the index)

We can also further aggregate to obtain just one score (or obtain
religious/ethnic score etc.).

Option also to discard them all (anti lgbtqi sentiment is also captured
in the next index built from `qc15`)

`qc6` also asks about discriminatory behaviors, but is about elected
public official, it does not ask about a situation that impacts you
personally. It also uses different categories for minorities therefore I
prefer to use `qc12` and `qc13` rather than `qc6`

<br>

SUPPORTIVE OF LGBTQ RIGHTS INDEX

Using `qc15` we can again build an index for how supportive of lgbtq
rights a person is.

I again choose to take the mean across the different answers but we
could also use median/mode if we think is better

If we feel each or some answers are particularly useful (given they are
closely related with our target variable) we can also use them
separately

We could also use `qc18` to try to capture anti lgbtq sentiment, but I
preferred `qc15` as it seemed more straightforward (I therfore deleted
`qc18`, but we can put it back if useful)

<br>

MY VOICE COUNTS

I guess that people that feel alienated from society and politics might
be less likely to support lgbtq rights so I took the mean of `d72`
question which asked whether you felt like your voice mattered

<br>

OTHERS

`qc11` is a strange question feels useless to me, I removed it for now
but we can think about it

I also removed `qc9` as I don't really know what to do with it and
`qc17`

```{r}
data <- data_raw |> 
  select(serialid, # unique identifier
         isocntry, # 2 digit country code
         d11, # age variables
         q1_29, # nationality of interviewee. options given: EU28+Other+DK, using only other = outside of EU
         d70, #life satisfaction
         polintr, # political interest index (summarizes d71 questions)
         starts_with("sd1"), # friends that are minority groups
         starts_with("sd2"), # are you part of a minority
         sd3, # religion
         qc2_15, # experienced discrimination yourself
         qc3, # where discrimination took place
         starts_with("qc5"), # actions against discrimination
         qc10, # how would you report discrimination
         starts_with("qc12"), # feelings about colleagues being minority
         starts_with("qc13"), # feelings about kid being in a relationship with minority
         starts_with("qc15"), # opinions about lgbtqi 
         qc19, # target variable transgender
         qc20, # non-binary genders in documents
         d1r1, # political ideology
         d7r1, # marital status
         d10, # gender binary
         d8, # eduaction 
         d15a_r2, # current occupation (discarded previous occupation d15b)
         d25, # rural vs urban
         d43t, # phones availiabilty
         d60, # financial stress (paying bills)
         netuse, # internet index
         d63, # social class
         starts_with("d72"), # my voice counts
  )

paradata <- data_raw |> 
  select(serialid, # to match it with the other data
         p2, p3, p3r, p4, p5, # paradata)
  )
```

Removing some of the previously selected variables

`sd2_7` to `sd2_10`: these are possible answer deemed irrelevant to the
question about yourself being part of the following minorities: `sd2_7`
other minorities (I don't know what other relevant minorities could be
there), `sd2_8` not part of minorities (can be deducted from the rest),
`sd2_9` refusal to respond, `sd2_10` DK answers `sd2t` summary binary
variable for being part of any minority (we are going to keep the more
specific one)

I also remove `qc12_nr` as I prefer to work on the full variable instead
of the recoded version with less categories. Same for `qc13` and `qc18`

```{r}
data <- data |> 
  # Keep in mind that sd2t does not have NAs so we might want to use that instead of the more specific ones
  select(-c(sd2_7, sd2_8, sd2_9, sd2_10, sd2t)) |> 
  select(-(starts_with("qc12") & ends_with("r"))) |> 
  select(-(starts_with("qc13") & ends_with("r"))) |> 
  select(-(starts_with("qc18") & ends_with("r")))
```

## Check overall data quality

```{r}
explore_tbl(data)
plot_intro(data)
```

All columns are numeric columns, the only one which is not is `isocntry`

```{r}
data |> 
  select(where(~ !is.numeric(.)))
```

Most columns do not have explicit NAs

```{r}
plot_missing(data)
names(which(colSums(is.na(data)) > 0))
```

Exploiting the fact that the .dta files has attributes (labels) for all
its columns.

If we search for `attr(colname, "label")` you get back the original long
name of the variable

If we instead search for `attr(colname, "labels")` you get back all the
possible encoding levels of the variable (ex.1,2,3,4 etc.) and by doing
`names(attr(colname, "labels"))` you get back the actual meaning of
those numbers (ex. 1 = "Yes", 2 = "No", etc.)

```{r}
# Extracting all the full names of the columns
variable_names <- tibble(
  var_code = names(data),
  var_full_name = sapply(data, function(col) attr(col, "label")))
variable_names
```

These long names df might be useful to rename the variables
systematically all together. Remember in case we filter out variables
after this code chunk and in case we use this df to rename variables
that there might be disalignments.

Will now look into the labels for the different levels that our factor
variables can take:

```{r}
attr(data$d70, "labels")
names(attr(data$d70, "labels"))
tibble(name_labels = names(attr(data$d70, "labels")),
       labels = attr(data$d70, "labels"))

# Create a list of tibbles containing the labels and their associated name for each variable
list_label_tibbles <- 
  #Applies a function across all columns of a df and returns results as a list
  lapply(names(data), function(col_name) {
    labels <- attr(data[[col_name]], "labels")  # Extract labels
    name_labels <- names(labels)  # Extract label names
    # Create tibble with the extracted data only if labels exist
    if (!is.null(labels)) {
      tibble(name_labels = name_labels, labels = labels)} 
    else {NULL}  # Returns a NULL element for columns without labels
  })

# Giving to each element of the list as name the name of the variable
list_label_tibbles <- setNames(list_label_tibbles, names(data))

# For example
list_label_tibbles$d70
```

Right column is what it appears in our data (as a number). Left column
is the label that we must assign to that number when we factorize

## Cleaning

### Initial cleaning and pre-processing

```{r}
# Recoding together Germany East and West because we are running analysis at the country level
unique(data$isocntry)
data <- data |> 
  mutate(isocntry = case_when(
    isocntry %in% c("DE-W", "DE-E") ~ "DE",
    TRUE ~ isocntry))
# We might want to join the full name of the countries using the codelist df
```

Separating variables for which I can use the attribute labels to
factorize them and the variables for which this strategy cannot be used

```{r}
data <- data |> 
  rename(friends_trans = sd1_7)

non_factor_variables <- c("serialid", "tnscntry", "isocntry", "d11", "q1_29", 
                          names(data)[startsWith(names(data), "sd1_")],
                          names(data)[startsWith(names(data), "sd2_")],
                          names(data)[startsWith(names(data), "qc5_")],
                          names(data)[startsWith(names(data), "qc12_")],
                          names(data)[startsWith(names(data), "qc13_")],
                          names(data)[startsWith(names(data), "qc15_")],
                          names(data)[startsWith(names(data), "d72_")],
                          "d8", "opls")
factor_variables <- setdiff(names(data), non_factor_variables)
```

Correctly encoding the factor variables that do not need any further
cleaning

```{r}
# Converting them to factors and assign them their labels automatically
data <- data |> 
  mutate(across(all_of(factor_variables), labelled::to_factor))

# Turning DK into NAs for all the factor variables
data <- data |> 
  mutate(across(all_of(factor_variables), ~ fct_na_level_to_value(., extra_levels = "DK")))

# Converting to numeric the variables that should be numeric
# They are already numeric but they carry with them some labels as well that only confuse us, by doing this I remove the labels
data <- data |> 
  mutate(age = as.numeric(d11),
         years_edu = as.numeric(d8)) |> 
  # Recoding correctly d8 education variable according to unique(data_raw$d11))
  mutate(years_edu = case_when(
    years_edu %in% c(0, 99) ~ NA, # Refusal and DK as NAs
    years_edu == 97 ~ 0, # No full time education = 0
    years_edu == 98 ~ age, # still studying = age
    TRUE ~ years_edu)) |> 
  select(-c(d11, d8))

# Converting q1_29 to factor without assigning labels (1 if non-Eu nationality, 0 if EU nationality)
# Same for sd2_
data <- data |> 
  mutate(nonEU_national = as.factor(q1_29),
         across(starts_with("sd2_"), ~ as.factor(.x))) |> 
  select(-q1_29)
```

Dealing with the other variables on which we do some further
pre-processing (feature engineering)

```{r}
# Creating a variable that counts the number of different minority groups a person has acquaintances with
data <- data |>  
  mutate(across(starts_with("sd1"), ~ if_else(.x == 1, 1, 0))) |> 
  mutate(n_friends_minorities = sd1_1+sd1_2+sd1_3+sd1_4+sd1_5+sd1_6+sd1_8) |> 
  relocate(n_friends_minorities, .before="sd1_1") |> 
  select(-starts_with("sd1"))

# Creating a variable that counts the number of actions against discrimination that you have taken in the last year
data <- data |>  
  mutate(across(starts_with("qc5"), ~ if_else(.x == 1, 1, 0))) |> 
  mutate(n_actions_against_discri = qc5_1+qc5_2+qc5_3+qc5_4) |> 
  relocate(n_actions_against_discri, .after="qc3") |> 
  select(-starts_with("qc5"))
```

```{r}
# Building a discriminatory score
data <- data |> 
  # Coding as NAs "it depends" and "DK"
  mutate(across(starts_with("qc12"), ~ if_else(.x >= 12, NA, .x))) |> 
  mutate(across(starts_with("qc13"), ~ if_else(.x >= 12, NA, .x))) |> 
  # Coding as 5 responses = indifferent
  mutate(across(starts_with("qc12"), ~ if_else(.x == 11, 5, .x))) |> 
  mutate(across(starts_with("qc13"), ~ if_else(.x == 11, 5, .x))) |> 
  # Modifying such that higher is more discriminatory
  mutate(roma_discri = 11 - rowMeans(cbind(qc12_1, qc13_1), na.rm = TRUE),
         black_discri = 11 - rowMeans(cbind(qc12_2, qc13_2), na.rm = TRUE),
         asian_discri = 11 - rowMeans(cbind(qc12_3, qc13_3), na.rm = TRUE),
         white_discri = 11 - rowMeans(cbind(qc12_4, qc13_4), na.rm = TRUE),
         jewish_discri = 11 - rowMeans(cbind(qc12_5, qc13_5), na.rm = TRUE),
         muslim_discri = 11 - rowMeans(cbind(qc12_6, qc13_6), na.rm = TRUE),
         buddihst_discri = 11 - rowMeans(cbind(qc12_7, qc13_7), na.rm = TRUE),
         christian_discri = 11 - rowMeans(cbind(qc12_8, qc13_8), na.rm = TRUE),
         atheist_discri = 11 - rowMeans(cbind(qc12_9, qc13_9), na.rm = TRUE),
         lgb_discri = 11 - rowMeans(cbind(qc12_10, qc13_10), na.rm = TRUE),
         trans_discri = 11 - rowMeans(cbind(qc12_11, qc13_11), na.rm = TRUE),
         intersex_discri = 11 - rowMeans(cbind(qc12_12, qc13_12), na.rm = TRUE),
         disability_discri = 11 - rowMeans(cbind(qc12_13, qc13_13), na.rm = TRUE),
         young_discri = 11 - rowMeans(cbind(qc12_14, qc13_14), na.rm = TRUE),
         old_discri = 11 - rowMeans(cbind(qc12_15, qc13_15), na.rm = TRUE)) |> 
  select(-starts_with("qc12")) |> 
  select(-starts_with("qc13"))

# I am deleting the discrimination index against young and old people
# This is because one of the question is: how comfortable you would feel if one of your children was in a love relationship with a person from group x.
# It is totally acceptable that people would not feel comfortable with their kid dating an old person without that accounting for being discriminatory against old people
data <- data |> 
  select(-c("old_discri", "young_discri"))
```

```{r}
# Supportive of lbtq rights index
data <- data |> 
  mutate(across(starts_with("qc15"), ~ if_else(.x == 5, NA, .x))) |>
  # Scale of 1 to 4, 1 = supportive, 4 = homophobic
  mutate(antilgbtq_rights = round(rowMeans(cbind(qc15_1, qc15_2, qc15_3), na.rm = TRUE), 2)) |> 
  select(-starts_with("qc15"))
```

```{r}
# My voice counts index
data <- data |> 
  mutate(across(starts_with("d72"), ~ if_else(.x > 4, NA, .x))) |>
  mutate(social_alienation = rowMeans(cbind(d72_1, d72_2), na.rm = TRUE)) |> 
  select(-starts_with("d72"))
# The higher the more people think their voice does not matter
```

This should be our final selection of variables.

We still need to rename them appropriately and check that all the NAs
are correctly encoded by looking at the summary.

Rename columns appropriately and move them around to order the dataframe

```{r}
data <- data |> 
  rename(
    country = isocntry,
    life_sat = d70,
    ethnic_minority = sd2_1,
    skincolor_minority = sd2_2,
    religious_minority = sd2_3,
    roma_minority = sd2_4,
    sexual_minority = sd2_5,
    disability_minority = sd2_6,
    religion = sd3,
    disc = qc2_15,
    disc_where = qc3,
    disc_contact = qc10,
    trans_docs = qc19,
    gender_docs = qc20,
    left_right = d1r1,
    marital_status = d7r1,
    gender = d10,
    occupation = d15a_r2,
    community = d25,
    phone_access = d43t,
    bill_issues = d60,
    internet_use = netuse,
    social_class = d63
  ) 
```

Now, we will transform the variable disc, which was originally coded in
a negative way (1 = "Not mentioned", 2 = "No, you haven’t been
discriminated against"), into a positive dummy variable to make its
interpretation more straightforward. The variable is 1 if a person has
been subject to discrimination

```{r}
data <- data |> 
  mutate(suffered_discr = as.factor(ifelse(disc == "Not mentioned", 1, 0))) |> 
  select(-disc) |> 
  relocate(suffered_discr, .before = disc_where)
```

```{r}
# Relocating to have a ordered df
data <- data |> 
  relocate(c("age", "gender", "years_edu","community", "marital_status", "occupation", "social_class", "religion", "nonEU_national", "phone_access", "bill_issues", "internet_use"), .after = country) |> 
  relocate(c("left_right", "social_alienation"), .after = polintr) |> 
  relocate(c("friends_trans", "n_friends_minorities", "n_actions_against_discri"), .after = gender_docs)

# Assigning labels to columns which have a difficult meaning
attr(data$gender, "label") <- NULL
attr(data$nonEU_national, "label") <- "OWNS A NON-EU NATIONALITY"
attr(data$social_alienation, "label") <- "HIGHER -> THINK THEIR VOICE DOESN'T  MATTER"
attr(data$ethnic_minority, "label") <- "ARE YOU PART OF X MINORITY" 
attr(data$skincolor_minority, "label") <- "ARE YOU PART OF X MINORITY" 
attr(data$religious_minority, "label") <- "ARE YOU PART OF X MINORITY" 
attr(data$roma_minority, "label") <- "ARE YOU PART OF X MINORITY" 
attr(data$sexual_minority, "label") <- "ARE YOU PART OF X MINORITY" 
attr(data$disability_minority, "label") <- "ARE YOU PART OF X MINORITY" 
attr(data$disability_minority, "label") <- "ARE YOU PART OF X MINORITY" 
attr(data$disability_minority, "label") <- "ARE YOU PART OF X MINORITY"
attr(data$suffered_discr, "label") <- "HAVE YOU BEEN SUBJECT TO DISCRIMINATION"
attr(data$n_friends_minorities, "label") <- "YOU KNOW PEOPLE FROM # NUMBER OF DIFFERENT MINORITES"
attr(data$n_actions_against_discri, "label") <- "YOU HAVE DONE # NUMBER OF DIFFERENT ACTIONS TO FIGHT DISCRIMINATIONS"
attr(data$roma_discri, "label") <- "HOW DISCRIMINATORY ARE YOU AGAINST X"
attr(data$black_discri, "label") <- "HOW DISCRIMINATORY ARE YOU AGAINST X"
attr(data$asian_discri, "label") <- "HOW DISCRIMINATORY ARE YOU AGAINST X"
attr(data$white_discri, "label") <- "HOW DISCRIMINATORY ARE YOU AGAINST X"
attr(data$jewish_discri, "label") <- "HOW DISCRIMINATORY ARE YOU AGAINST X"
attr(data$muslim_discri, "label") <- "HOW DISCRIMINATORY ARE YOU AGAINST X"
attr(data$buddihst_discri, "label") <- "HOW DISCRIMINATORY ARE YOU AGAINST X"
attr(data$christian_discri, "label") <- "HOW DISCRIMINATORY ARE YOU AGAINST X"
attr(data$atheist_discri, "label") <- "HOW DISCRIMINATORY ARE YOU AGAINST X"
attr(data$atheist_discri, "label") <- "HOW DISCRIMINATORY ARE YOU AGAINST X"
attr(data$lgb_discri, "label") <- "HOW DISCRIMINATORY ARE YOU AGAINST X"
attr(data$trans_discri, "label") <- "HOW DISCRIMINATORY ARE YOU AGAINST X"
attr(data$intersex_discri, "label") <- "HOW DISCRIMINATORY ARE YOU AGAINST X"
attr(data$disability_discri, "label") <- "HOW DISCRIMINATORY ARE YOU AGAINST X"
attr(data$antilgbtq_rights, "label") <- "HIGHER -> THEY OPPOSE MORE RIGHTS TO LGBTQ"
```

```{r}
summary(data)
```

Our dataset seems quite balanced across the different countries

```{r}
data |> count(country)
```

Although some levels of occupation have more observations than others,
we have enough observations for each level so we do not need to
aggregate over different levels for the variable `occupation`

```{r}
data |> count(occupation)
```

Very few people declare themselves to be the higher class of society,
nonetheless we keep this level because it makes sense

```{r}
data |> count(social_class)
```

Given the low number of observations in some categories of the variable `religion` and the high number of categories we opt to aggregate some of them, otherwise we risk too much noise in our models.

```{r}
data |> count(religion)

# Checking if the means of groups we are going to aggregate are similar
data |> 
  mutate(trans_docs=as.numeric(trans_docs)) |> 
  summarise(mean = mean(trans_docs, na.rm=TRUE), .by = religion) |>
  arrange(mean)

# We are going to group together atheist with agnostic
# We are also going to put sikh, buddhists, jewish and hindu into the other category
# Finally we are going to group together all muslims
data <- data |> 
  mutate(religion = fct_collapse(religion,
                                "Non-believers" = c("Atheist", "Non believer or agnostic"),
                                "Other" = c("Sikh", "Buddhist", "Jewish", "Hindu", "Other"),
                                "Muslim" = c("Muslim - Shia", "Muslim - Sunni", "Other Muslim")))

#This is what we end up with
data |> count(religion)
```

### Recoding missing values

Now we will substitute de "Refusal" answers in the remaining variables
as NAs. If the respondent refuses to answer it's equivalent to not
knowing his or her answer. We exclude friends_trans because that
category could be worth analyzing.

```{r}
factor_variables <- names(data)[sapply(data, is.factor)]

data <- data %>%
  mutate(across(
    all_of(setdiff(factor_variables, "friends_trans")),  # Exclude "friends_trans"
    ~ {
      # Look for levels that contain "REFUSAL"
      refusal_levels <- grep("REFUSAL", levels(.), value = TRUE, ignore.case = TRUE)
      # If there are levels containing "REFUSAL"
      if (length(refusal_levels) > 0) { 
        # Convert in NA
        fct_recode(., NULL = refusal_levels)  
      } 
      # if not remain without changes
      else {
        .  
      }
    }
  ))

# Mutate NONE level of social class to NA
data <- data %>%
  mutate(social_class = fct_recode(social_class, NULL = "None (SPONTANEOUS)"))

# We turn marital_status level OTHER into NAs, as it is difficult to give it any other meaning. Same for social class
data <- data %>%
  mutate(marital_status = fct_recode(marital_status, NULL = "Other (SPONT.)"),
         social_class = fct_recode(social_class, NULL = "Other (SPONTANEOUS)")) 
```

```{r}
plot_intro(data)
plot_missing(data)
```

The total number of missing observations is quite low (4%) so missing
data should not be a huge problem

Given the high percentage of missing values we delete `disc_where`. This
variable was expected to have a high percentage of missingness as it is
a question that applies only to people that have been subject to
discrimination.

The variable with the second highest number of missing data is
`left_right`, given the importance of this variable it is probably worth
to impute those values.

Next there are the variables `trans_docs` and `gender_docs` which are
respectively our target variable and a closely related variable

Then there is `disc_contact` which will be deleted as well, given that
it does not add meaningful information to our analysis

```{r}
data <- data |> 
  select(-c("disc_where", "disc_contact"))
```

# Joining together country-level data

```{r}
country_level_data <- codelist |> 
  select(iso3c, iso2c) |> 
  left_join(gdp_data, by = c("iso3c" = "country_code")) |> 
  # left_join(rural_data, by = c("iso3c" = "country_code")) |> rural population data will probably be discarded
  left_join(gender_index, by = c("iso3c" = "country_iso_code")) |> 
  left_join(lgbt_rights_index, by = c("iso3c" = "country_code")) |> 
  left_join(democracy_index, by = c("iso3c" = "country_code")) |> 
  select(-contains("country_")) # removing all duplicated country_name columns that were joined from each data frame
str(country_level_data)
```

Not using paradata for now. We can discuss how to use it

```{r}
complete_df <- data |> 
  left_join(country_level_data, 
            by = join_by(country == iso2c)) |> 
  select(-c(country.y, iso3c))
```

# Exploratory Data Analysis

Plotting the distribution of the numeric variables

```{r}
library(e1071)

# Identify numeric variables
numeric_vars <- names(data)[sapply(data, is.numeric)]

# Creating histogramas y calculating skweness
for (var in numeric_vars) {
  p <- ggplot(data, aes(x = .data[[var]])) +
    geom_histogram(binwidth = 1, fill = "blue", color = "black") +
    labs(title = paste("Histogram of", var), x = var, y = "Count") +
    theme_minimal()
  print(p)
  
  skew <- skewness(data[[var]], na.rm = TRUE)
  cat("Skewness of", var, ":", skew, "\n")
  
  # Suggest transformation if skeness is high
  if (abs(skew) > 1) {
    cat("--> Consider applying a logarithmic transformation to", var, "\n")
  }
}
```

## Analysis of individual-level variables

We must keep in mind our Target variable is qc19 "Do you think that
transgender persons should be able to change their civil documents to
match their inner gender identity?"

```{r}
data_percent <- data |> 
  group_by(trans_docs) |> 
  summarise(count = n()) |> 
  mutate(percentage = count / sum(count) * 100)

ggplot(data_percent, aes(x = trans_docs, y = percentage, fill = trans_docs)) +
  geom_bar(stat = "identity") +  
  geom_text(aes(label = sprintf("%.1f%%", percentage)),  
            vjust = -0.5, size = 4, color = "black") +  
  scale_y_continuous(labels = scales::percent_format(scale = 1)) + 
  labs(
    title = "Overall distribution of support for trans people to change \ntheir gender in civil documents",
    x = "Support for Transgender Rights",
    y = "Percentage"
  ) +
  theme_minimal() +
  theme(legend.position = "none")
```

Taking a look to our variable of interest alone, we see how the 52.7% of
our sample are in favor of trans people to change their gender in their
civil documents. However, there is also a significant opposition
(35,3%), and a 12% who answered "Don't know". We will try to explore
this distribution along the variables we consider to be most important
for our analysis.

--\> When we turned DK into NAs for all the factor variables, we also
changed it for qc19 (now trans_docs). We should keep throughout our
analysis in mind that NAs for qc19 are actually DK. Later we can code it
as DK instead of NAs to have better graphs.

### Sociodemographic variables

#### Gender

```{r}
data_summary <- data |> 
  count(trans_docs, gender, name = "n") |> 
  group_by(gender) |>  
  mutate(percentage = n / sum(n))  

ggplot(data_summary, aes(x = trans_docs, y = percentage, fill = gender)) +
  geom_bar(stat = "identity", position = "dodge") +  
  geom_text(aes(label = scales::percent(percentage, accuracy = 1)),  
            position = position_dodge(width = 0.9), vjust = -0.2, size = 4) +  
  scale_y_continuous(labels = percent_format()) + 
  labs(
    title = "Distribution of support by gender",
    x = "Support for trans people changing their civil documents",
    y = "Percentage within Gender",
    fill = "Gender"
  ) +
  theme_minimal()

# Crear una tabla de contingencia
contingency_table <- table(data$gender, data$trans_docs)

# Realizar la prueba de chi-cuadrado
chisq_test <- chisq.test(contingency_table)
print(chisq_test)
```

Men exhibit a lower percentage of favorable or dk responses and a higher
rate of rejection compared to women. There is a statistically
significant association between gender and our target variable, being
women more supportive

#### Age

```{r}
#ANOVA
anova <- aov(age ~ trans_docs, data = data)
summary(anova)
```

There are significant differences between the groups defined by
trans_docs.

#### Religiosity

We have two variables related to religiosity: religion (the religious
affiliation professed by the respondent) and religious_minority (whether
or not the respondent belongs to a religious minority group).

For the first one it's better to show a cross table instead of a plot,
since there are a lot of categories

```{r}
CrossTable(data$religion, data$trans_docs,
           digits = 2, 
           expected = FALSE, 
           asresid = TRUE, 
           chisq = TRUE, 
           prop.chisq = FALSE, 
           format = "SPSS")
```

Out of all observations Catholic, non-believers, Orthodox Christians
and Protestants sum up to the 81.04% of our sample, being the rest
underrepresented.

```{r}
data_summary <- data |> 
  count(trans_docs, religious_minority, name = "n") |> 
  group_by(religious_minority) |>  
  mutate(percentage = n / sum(n))  

ggplot(data_summary, aes(x = trans_docs, y = percentage, fill = religious_minority)) +
  geom_bar(stat = "identity", position = "dodge") +  
  geom_text(aes(label = scales::percent(percentage, accuracy = 1)),  
            position = position_dodge(width = 0.9), vjust = -0.2, size = 4) +  
  scale_y_continuous(labels = percent_format()) + 
  labs(
    title = "Distribution of support by religious minority",
    x = "Support for trans people changing their civil documents",
    y = "Percentage within religious_minority",
    fill = "religious_minority"
  ) +
  theme_minimal()
```

#### Ideology

```{r}
data_summary <- data |> 
  count(trans_docs, left_right, name = "n") |> 
  group_by(left_right) |>  
  mutate(percentage = n / sum(n))  

ggplot(data_summary, aes(x = trans_docs, y = percentage, fill = left_right)) +
  geom_bar(stat = "identity", position = "dodge") +  
  geom_text(aes(label = scales::percent(percentage, accuracy = 1)),  
            position = position_dodge(width = 0.9), vjust = -0.2, size = 4) +  
  scale_y_continuous(labels = percent_format()) + 
  labs(
    title = "Distribution of support by ideology",
    x = "Support for trans people changing their civil documents",
    y = "Percentage within ideology",
    fill = "ideology"
  ) +
  theme_minimal()
```

Stronger left-wing support for trans rights. Right-wing respondents are
the most divided, with high opposition levels. Non-responses are highest
among those without ideological alignment.

#### Social class

```{r}

data_summary <- data |> 
  count(trans_docs, social_class, name = "n") |> 
  group_by(social_class) |>  
  mutate(percentage = n / sum(n))  

ggplot(data_summary, aes(x = trans_docs, y = percentage, fill = social_class)) +
  geom_bar(stat = "identity", position = "dodge") +  
  geom_text(aes(label = scales::percent(percentage, accuracy = 1)),  
            position = position_dodge(width = 0.9), vjust = -0.2, size = 4) +  
  scale_y_continuous(labels = percent_format()) + 
  labs(
    title = "Distribution of support by social class",
    x = "Support for trans people changing their civil documents",
    y = "Percentage within social class",
    fill = "social class"
  ) +
  theme_minimal()
```

Although D63 of the questionnaire measures (oneself's and one's
household's) self-perceived social class, it is still a relevant and
seemingly divisive variable. We observe a positive correlation, where
support grows with increasing (perceived) social class, while explicit
lack of support and no response are higher for lower-class individuals.

#### Education

```{r}
ggplot(data, aes(x = trans_docs, y = years_edu)) +
  geom_violin() +
  labs(x = "Support for trans people changing their civil documents", y = "Age when stopped full-time education") +
  ggtitle("Distribution of support by education")
```

Support doesn't seem to be related to education.

#### Area of residence

```{r}
data_summary <- data |> 
  count(trans_docs, community, name = "n") |> 
  group_by(community) |>  
  mutate(percentage = n / sum(n))  

ggplot(data_summary, aes(x = trans_docs, y = percentage, fill = community)) +
  geom_bar(stat = "identity", position = "dodge") +  
  geom_text(aes(label = scales::percent(percentage, accuracy = 1)),  
            position = position_dodge(width = 0.9), vjust = -0.2, size = 4) +  
  scale_y_continuous(labels = percent_format()) + 
  labs(
    title = "Distribution of support by area of residence",
    x = "Support for trans people changing their civil documents",
    y = "Percentage within area of residence",
    fill = "area of residence"
  ) +
  theme_minimal()
```

Support does not vary much by area of residence.

### Other individual-level variables

#### Having trans friends

```{r}
data_summary <- data |> 
  count(trans_docs, friends_trans, name = "n") |> 
  group_by(friends_trans) |>  
  mutate(percentage = n / sum(n))  

ggplot(data_summary, aes(x = trans_docs, y = percentage, fill = friends_trans)) +
  geom_bar(stat = "identity", position = "dodge") +  
  geom_text(aes(label = scales::percent(percentage, accuracy = 1)),  
            position = position_dodge(width = 0.9), vjust = -0.2, size = 4) +  
  scale_y_continuous(labels = percent_format()) + 
  labs(
    title = "Distribution of support by haivng trans friends",
    x = "Support for trans people changing their civil documents",
    y = "Percentage within groups",
    fill = "Has Trans Friends"
  ) +
  theme_minimal()

```

Having trans friends is associated with a higher support, while those
who refuse to disclose their connections to trans people tend to oppose
more.

## Country-level data

Replication of the plot in Marga's document. This is probably not needed
in the final version of the document.

```{r}
country_support <- data %>%
  mutate(
    trans_docs = case_when(
      is.na(trans_docs) ~ "DK",
      trans_docs == "Yes" ~ "1",
      trans_docs == "No" ~ "2",
      TRUE ~ as.character(trans_docs)
    )
  ) %>%
  group_by(country, trans_docs = trans_docs) %>%
  summarise(count = n(), .groups = "drop") %>%
  group_by(country) %>%
  mutate(proportion = (count / sum(count))*100) %>%
  ungroup()

ggplot(country_support, aes(x = factor(country, levels = country_support %>%
                                       filter(trans_docs == "1") %>%
                                       arrange(desc(proportion)) %>%
                                       pull(country)), 
                           y = proportion,
                           fill = factor(trans_docs, levels = c("1", "2", "DK")))) +
  geom_bar(stat = "identity", position = position_stack(reverse = TRUE)) +
  scale_fill_manual(values = c("1" = "#497ba9", "2" = "#d56e6e", "DK" = "#9a9595"),
                   name = "",
                   labels = c("Yes", "No", "Don't know")) +
  geom_text(aes(label = round(proportion)), 
          position = position_stack(reverse = TRUE, vjust = 0.5),
          size = 3.5, color = "white") +
  labs(
    title = "QC9: Do you think transgender persons should be able to change their civil documents to match their inner gender identity?",
    x = "", 
    y = ""
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        axis.text.y = element_blank(),
        axis.ticks.y = element_blank(),
        plot.title = element_text(size = 9),
        panel.grid.major.y = element_blank(),
        legend.position = "bottom")
```

There are some mismatches, I guess the data might have become distorted
at some point during processing, but I don't know when.

```{r}
trans_docs_prop <- country_support %>%
  filter(trans_docs == "1") %>%
  select(country, proportion) %>%
  rename(trans_support = proportion)

country_long <- country_level_data %>%
  inner_join(trans_docs_prop, by = c("iso2c" = "country")) |> 
  pivot_longer(cols = c(gdp_pc_ppp, gender_inequality_index, lgbt_policy_index, democracy_index),
    names_to = "variable", values_to = "value")

ggplot(country_long, aes(x = value, y = trans_support)) +
  geom_smooth(method = "lm", se = FALSE, color = "lightgray") + # we can remove this
  geom_point(size = 2, color = "blue", alpha = 0.7) +
  geom_text(aes(label = iso3c), vjust = -0.5, hjust = 0.5, size = 3) +
  facet_wrap(~variable, scales = "free_x") +
  labs(
    title = "Relationship between country-level variables and trans support",
    x = "Country-level variable",
    y = "Proportion of Yes answers"
  ) +
  theme_minimal()
```

Democracy and LGBT Policy indeces seem to have a positive linear
relationship with the target variable, while Gender Inequality index has
a negative linear relationship. The relationship with GDP per capita is
non-linear (logarithmic?). There appears to be a "ceiling" of support,
beyond which increases in GDP per capita lose effect.

Boxplots for country-level variables:

```{r}
ggplot(country_long, aes(y = value, x = variable)) +
  geom_boxplot(outlier.color = "red", outlier.shape = 16, fill = "lightblue") +
  coord_flip() +
  theme_minimal() +
  labs(title = "Distribution of country-level variables", x = NULL, y = "value") +
  facet_wrap(~variable, scales = "free") +
  theme(axis.text.y = element_blank(),  
        axis.ticks.x = element_blank())
```

Histograms of scaled country data:

```{r}
# scaled_data <- country_level_data %>%
#   select(-iso3c, -iso2c, -country) %>%
#   mutate(across(everything(), scale)) %>%  # Standardize all variables
#   pivot_longer(cols = everything(), names_to = "variable", values_to = "value")
# 
# # Plot histograms
# ggplot(scaled_data, aes(x = value)) +
#   geom_histogram(fill = "lightblue", bins = 17) +
#   facet_wrap(~variable, scales = "free_y") +
#   theme_minimal() +
#   labs(title = "Distribution of scaled country-level Variables", x = "Standardized Value", y = "Count")
```

```{r}
country_level_data <- country_level_data %>%
  inner_join(trans_docs_prop, by = c("iso2c" = "country"))

cor_matrix <- cor(country_level_data %>%
                    select(gdp_pc_ppp, democracy_index, gender_inequality_index, 
                           lgbt_policy_index, trans_support),
                  use = "complete.obs")

corrplot(cor_matrix, method = "color", type = "upper", 
         addCoef.col = "black", tl.col = "black",
         col = colorRampPalette(c("blue", "white", "red"))(200))
```

## Paradata

```{r}
# Extracting labels in paradata
list_label_tibbles_paradata <- lapply(names(paradata), function(col_name) {
  labels <- attr(paradata[[col_name]], "labels")  
  name_labels <- names(labels)  
  if (!is.null(labels)) {
    tibble(name_labels = name_labels, labels = labels)
  } else {
    NULL
  }
})

# Asign names to list elements
list_label_tibbles_paradata <- setNames(list_label_tibbles_paradata, names(paradata))

# Convert into factor
paradata <- paradata %>%
  mutate(across(where(~ !is.null(attr(., "labels"))), labelled::to_factor))

# Merging datasets for the analysis
merged_paradata <- merge(data, paradata, by = "serialid", all.x = TRUE)
```

Number of persons present during interview:

```{r}
library(gmodels)

# Convert NA in a explicit category
merged_paradata$trans_docs <- as.character(merged_paradata$trans_docs)   
merged_paradata$trans_docs[is.na(merged_paradata$trans_docs)] <- "DK"  
merged_paradata$trans_docs <- as.factor(merged_paradata$trans_docs)  

# CrossTable
CrossTable(merged_paradata$p4, merged_paradata$trans_docs,
           digits=2, 
           expected=F, 
           asresid=T, 
           chisq=TRUE, 
           prop.chisq=F, 
           format="SPSS")

```

The table shows a significant association between the number of people
present during the interview and support for transgender people to
change their documents

Regarding the duration of the interview we have 2 options p3 and p3r. We
will use p3r to have a simpler analysis

```{r}
# CrossTable
CrossTable(merged_paradata$p3r, merged_paradata$trans_docs,
           digits=2, 
           expected=F, 
           asresid=T, 
           chisq=TRUE, 
           prop.chisq=F, 
           format="SPSS")

```

Respondent cooperation

```{r}

data_summary <- merged_paradata |> 
  count(p5, trans_docs, name = "n") |> 
  group_by(p5) |>  
  mutate(percentage = n / sum(n))  

ggplot(data_summary, aes(x = p5, y = percentage, fill = trans_docs)) +
  geom_bar(stat = "identity", position = "dodge") +  
  geom_text(aes(label = scales::percent(percentage, accuracy = 1)),  
            position = position_dodge(width = 0.9), vjust = -0.2, size = 4) +  
  scale_y_continuous(labels = percent_format()) + 
  labs(
    title = "Distribution of support by Respondent cooperation",
    x = "Respondent cooperation",
    y = "Percentage within groups",
    fill = "Support"
  ) +
  theme_minimal()


# Calcular porcentajes
plot_data <- merged_paradata %>%
  group_by(p5, trans_docs) %>%
  summarise(count = n(), .groups = 'drop') %>%
  mutate(percentage = count / sum(count) * 100)

```

Respondents who engaged better in the survey were more likely to express
support.

# Correlation and multicollinearity

Now we want to take a look at the possible multicollinearity of our explanatory variables. For it, we calculate the correlation of our numerical variables. As we have too many variables, we visualize just those with a strong correlation to focus on key dependencies.

```{r}

cor_matrix <- cor(data %>%
                    select_if(is.numeric) %>%
                    select(-serialid),
                  use = "complete.obs")

corrplot(cor_matrix, method = "color", type = "upper", 
         addCoef.col = "black", tl.col = "black",
         col = colorRampPalette(c("blue", "white", "red"))(200))


# Create a matrix where only correlations >= 0.7 are maintained
cor_filtered <- ifelse(abs(cor_matrix) >= 0.7, cor_matrix, NA)

# Graph
corrplot(cor_filtered, method = "color", type = "upper", 
         addCoef.col = "black", tl.col = "black",
         col = colorRampPalette(c("blue", "white", "red"))(200),
         na.label = " ",
         insig = "blank") 
```

Most strong correlations are among variables related race, religion or sexual orientation discrimination. Consequently, we are grouping them into 3 new composite variables by averaging related ones, in order to reduce multicollinearity.

```{r}
# Creating grouped variables
data <- data %>%
  mutate(
    racial_discri = rowMeans(select(., roma_discri, black_discri, asian_discri), na.rm = TRUE), #no white
    sexual_discri = rowMeans(select(., lgb_discri, trans_discri, intersex_discri), na.rm = TRUE),
    religious_discri = rowMeans(select(., jewish_discri, muslim_discri, buddihst_discri), na.rm = TRUE)
  ) 

# Removing original variables to avoid redundancy
data <- data |> 
  select(-c(roma_discri, black_discri, asian_discri, lgb_discri, trans_discri, intersex_discri, jewish_discri, muslim_discri, buddihst_discri))


# Graphical representation
cor_matrix <- cor(data %>%
                    select_if(is.numeric) %>%
                    select(-serialid),
                  use = "complete.obs")


corrplot(cor_matrix, method = "color", type = "upper", 
         addCoef.col = "black", tl.col = "black",
         col = colorRampPalette(c("blue", "white", "red"))(200))
```

We realize our new variables are still highly correlated between them. For reducing the dimensionality of the dataset even more while preserving information we create one single variable for general minority discrimination.

```{r}

# Creating grouped variable
data <- data %>%
  mutate(
    minority_discri = rowMeans(select(., racial_discri, sexual_discri, religious_discri, disability_discri), na.rm = TRUE)) 

```

We decided to exclude white_discri, atheist_discri, christian_discri because we realized they had a median of 1 and a quite small mean, meaning there is almost no reported discrimination against these groups in the dataset.

```{r}

summary(data$white_discri)
summary(data$atheist_discri)
summary(data$christian_discri)

data <- data |> 
  select(-c(white_discri, atheist_discri, christian_discri, racial_discri, sexual_discri, religious_discri, disability_discri))

```
Final check of the correlation matrix to confirm that multicollinearity has been reduced.
```{r}
cor_matrix <- cor(data %>%
                    select_if(is.numeric) %>%
                    select(-serialid),
                  use = "complete.obs")


corrplot(cor_matrix, method = "color", type = "upper", 
         addCoef.col = "black", tl.col = "black",
         col = colorRampPalette(c("blue", "white", "red"))(200))
```

# Class imbalance

```{r}
prop.table(table(data$trans_docs, useNA = "ifany"))
prop.table(table(data$trans_docs, useNA = "no"))
```

Our target variable has a 60/40 distribution so we are not worried about class imbalance.

Less represented classes in other variables have already been aggregated if deemed necessary.

# Analysis of missing values.

Here we analyse the NA reponses to our target variable. This is a sort
of robustness check to understand our data and learn if there are
patterns in NA response that we should be worried about e.g. if there
are specific demographics of people are less likely to respond.

Overall the analysis below shows that non response is similar to the
descriptive data and aligned with some groups reported "No" to
supporting trans_docs in c19. So we're more at risk of underreporting
"no" votes in this survey due to non-response. The correlation is low
though so it's not a major concern.

## Who is more likely to not respond to our target? 

There are 3,280 NA responses to the target variable. To try understand
if the missing values are at random, we will test the correlation
between NA response and Use the DK (don't know) for our target variable.

In the descriptive analysis above, we have already seen in raw terms
that NA responses were more frequent from some groups e.g.

-   women,

-   older people,

-   people who also responded NA for political ideology,

-   People who do not have trans friends and those who refused to
    respond to the friendship question had higher NA responses to the
    target variable.

-   People with lower survey cooperation

-   By country, we already understand from the challenge description
    that the NA responses vary. This is a significant disparity.

Create a binary variable for the DK

```{r}
cntry_name <- codelist |> select(iso2c, country_name = country.name.en)
dk_target <- data |> 
  mutate(target_NA = ifelse(is.na(trans_docs), 1, 0)) |> 
  left_join(cntry_name, by = join_by(country == iso2c)) |> 
  dplyr::select(-trans_docs, -serialid, -country)

table(dk_target$target_NA)
```

Confirm DK rates by country. They vary from 1.4% in Belgium to 28.5% in
Bulgaria. Overall, the average is 11.95%.

```{r}
dk_target |> 
  group_by(country_name) |> 
  summarise(count_na = sum(target_NA),
            num_resp = length(country_name),
            pct_na = count_na/num_resp*100) |> 
  ggplot(aes(x=reorder(country_name, -pct_na), y = pct_na))+
  geom_col()+
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        axis.title.x = element_blank()) +
  scale_y_continuous(labels = scales::percent_format(scale = 1)) + 
  labs(y = "Proportion of NA responses")

```

If all NA responses to the target are removed, this is how much the
"Yes" count increases for each of our countries. We see this is not
proportional. This is a statistical phenomenon. distribution of the
variable looks by country. The NA vote removal, makes our differences in
Yes/No differences appear larger.

```{r}

data |> 
  group_by(country) |> 
  summarise(yes_count = sum(trans_docs == "Yes", na.rm=TRUE),
            num_resp = sum(!is.na(trans_docs)),
            num_na = sum(is.na(trans_docs)),
            pct_yes_withna = yes_count / length(country)*100,
            pct_yes = yes_count/num_resp*100)|> 
  ggplot(aes(x = reorder(country, -pct_yes))) +
  geom_col(aes(y = pct_yes), fill = "red") + # First bar (pct_yes)
  geom_col(aes(y = pct_yes_withna), fill = "yellow", alpha = 0.5) + # Second bar (pct_yes_withna)
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        axis.title.x = element_blank()) +
  scale_y_continuous(labels = scales::percent_format(scale = 1),
                     limits = c(0,100)) + 
  labs(title ="Support for transgender rights to legally change documents, with and without NA's")


```

### Check correlation with DK of target

Run model to test what is correlated with DK response, use Cramers V for
association between the factor variables and correlation for the numeric
variables in the cleaned data.

1.  Model the data for DK responses against the factor variables.

```{r}
factor_subset <- dk_target %>%
  dplyr::select(target_NA, where(is.factor)) |> 
  mutate(target_NA = factor(target_NA))

### Run cramers V for factors
library(DescTools)

target_var <- "target_NA"
factor_variables <- names(factor_subset)
factor_variables <- factor_variables[factor_variables != target_var]

cramers_v_results <- list()

for (variable in factor_variables) {
    contingency_table <- table(factor_subset[[target_var]], 
                               factor_subset[[variable]])
    cramers_v <- CramerV(contingency_table)
    cramers_v_results[[variable]] <- cramers_v
}

# Create a Tibble for Results
cat_results <- tibble(variable = names(cramers_v_results),
       cramers_v = unlist(cramers_v_results)) |> 
  arrange(desc(cramers_v))
cat_results

```

This shows all of the factors have quite low association with the NA
responses. The highest being internet use. This is a good sign that the
missing values are random.

2.  Look at the numeric variables and test correlations:

```{r}
numeric_subset <- dk_target %>%
  dplyr::select(target_NA, where(is.numeric)) 

target_var <- "target_NA"
numeric_variables <- names(numeric_subset)[names(numeric_subset) != target_var]

cor_results <- list()

for (variable in numeric_variables) {
    correlation <- cor(numeric_subset$target_NA, 
                       numeric_subset[[variable]],
                       use = "pairwise.complete.obs")
    cor_results[[variable]] <- correlation
}

# Create a Tibble for Results
cor_results <- tibble(variable = names(cor_results),
       cor = unlist(cor_results)) |> 
  arrange(cor)
cor_results

```

Again, this is not too much cause for concern. We only have around 10%
correlations, positive and negative with the target variable.

### Modelling relationship with key variables and non-response

Here we run a logistic regression to test for the most
important/significant variables. First, we make a subset of data with
only our variables that were most correlated in the seciton above (use
above +/- 9.5% correlation and above 10% cramers V) and also include
gender and country.

```{r}

cor_results |> filter(cor > 0.09 | cor < -0.9) |> pull(variable)
cat_results |> filter(cramers_v >0.1) |> pull(variable)

```

Now model with those variables to see if they are significant in
explaining the DK values. Gender will also be included as a key
variable.

We run a stepwise AIC on these most correlated variables and then use
the best model to test the overall model fit.

```{r}
# first, run stepwise to determine most important 
# run base model 
dk_fit_null <- glm(target_NA ~ 1,
              data = dk_target, 
              family = "binomial")
# run full fit model of most correlated vars with country (also age^2 for good practice)
dk_fit <- glm(target_NA ~ gender + age + I(age*age) + antilgbtq_rights + internet_use + social_class + country_name, 
              data = dk_target, 
              family = "binomial")

# use stepwise to select best mode l
aic_1 <- MASS::stepAIC(dk_fit, scope = list(upper = dk_fit, 
                             lower = dk_fit_null),
        direction = "both", k = 2, trace=0) # forward based on AIC

# filter vars significant at 5% and calculate exponential
broom::tidy(aic_1) |> 
  filter(p.value<0.05) |> 
  mutate(oddsratio = exp(estimate)) |> 
  select(term, oddsratio, p.value)
  
```

The best model is the one without age but includes age\^2. So we run the
full model to keep the lower level variables included.

The model has some interesting findings to who did not respond to our
findings. Some things we can see with the odds ratios (excluding
interpretation of countries as that is covered above):

-   women are around 20% more likely to give NA responses

-   Anti-lgbti rights people were about 10% more likely to not respond

-   Internet use was significant but is not interpertable. If you had
    not used the internet (higher NA likelihood) or used it 2-3 times a
    week (lower NA likelihood) compared to everyday use

-   Social class was significant at all levels, compared to the working
    class, you were more likely to not respond to our target variable if
    you reported being in the lower middle, middle or upper middle
    class. I.e. working class were less likely to answer this question.

\~\~\~\~\~\~\~\~\~ SHOULD WE DELETE THIS SECTION ON UNDERSAMPLING/CLASS
IMBALANCE\~\~\~\~

Below is an option using undersampling which is probably more legit too.
maybe good to include if we aren't doing in other sections.

```{r}
# split to test and training
na_model <- glm(target_NA ~ .,
                      data = dk_target, 
                      family = "binomial")
summary(na_model)
broom::tidy(na_model)

exp(coefficients(na_model))
```

Approach to test relationship to DK with splitting and undersampling:

```{r}
# create new dataset with just vars we want, including age^2
dk_target2 <- dk_target |> 
  select(target_NA, age, antilgbtq_rights, internet_use, social_class, country_name) |> 
  mutate(age_sq = age*age, .after = age)

# to deal with some class imbalance, undersample from the majority group (NA = 0)
set.seed(123)
# Generate an index
index <- createDataPartition(dk_target2$target_NA, p = 0.7, list = FALSE, times = 1)

# Subset the dataframe
train <- dk_target2[index, ]
test <- dk_target2[-index, ]
# check splits 
prop.table(table(train$target_NA))
prop.table(table(test$target_NA))
```

Now undersample the majority

```{r}
set.seed(123)
under <- ovun.sample(target_NA~., 
                     data=train, 
                     method = "under", 
                     N = 4000)$data 
    # limit the sample to 4000 obs as we have ~2300 for target minority class. 

table(under$target_NA)

#run the rf model 
rfunder <- randomForest(target_NA~., data=under)
rfunder
```

We see that only around 5% of the variance is explained.

\~\~\~ REMOVE TO HERE IF WE DON'T WANT THE ABOVE

### Testing the NA values against paradata

Here we extend the model to see if paradata is related to changed
non-response.

```{r}
para <- paradata |> 
  bind_cols(trans_docs = data$trans_docs,
            age = data$age,
            gender = data$gender,
            country = data$country) |> 
  mutate(target_NA = ifelse(is.na(trans_docs), 1, 0)) |> 
  select(-serialid, -trans_docs)

summary(para$target_NA)
str(para)
```

First, again test correlation. We use Cramers V since we only have
factors:

```{r}
target_var <- "target_NA"
para_vars <- names(para)[names(para) != target_var]

cramers_v_results <- list()

for (variable in para_vars) {
    contingency_table <- table(para[[target_var]], 
                               para[[variable]])
    contingency_table_no_dk <- contingency_table[, colnames(contingency_table) != "DK"]
    cramers_v <- CramerV(contingency_table_no_dk) 
    # include this for no DK as it is all zero which creates errors
    cramers_v_results[[variable]] <- cramers_v
}


# Create a Tibble for Results
tibble(variable = names(cramers_v_results),
       cramers_v = unlist(cramers_v_results)) |> 
  arrange(desc(cramers_v))

```

Again, we see low correlation with the paradata and cramers V.

Second, we run another logistic model with just Paradata included.

```{r}
na_para_model <- glm(target_NA ~ p2 + p3r + p4 + p5 + age + I(age*age) + gender + factor(country), 
                     data = para, 
                     family=binomial(link = "logit"))

broom::tidy(na_para_model) |> 
  filter(p.value<0.05) |> 
  mutate(oddsratio = exp(estimate)) |> 
  select(term, oddsratio, p.value)
```

We see that when controlling for age, gender and country, the survey
cooperation variable is significant.

When compared to those with an excellent cooperation rating, people were
more likely to respond. This increases with lacking cooperation. If
cooperation was fair, there was around 40% more chance of NA, if
cooperation was average, around 75% higher chance of NA. If cooperation
was bad, there was about 350% higher chance of a NA response to our
target variable.

Overall, the correlations with our target variables are low which means
we don't have a major concern. Some are interesting e.g. interview
cooperation. The worse the cooperation, the more likely to not respond
to the question. This could be underreporting No votes, because as we
saw in the descriptive analysis, the worse the cooperation, the higher
the No vote for supporting trans_docs. There could also be some reverse
causality, as not responding leads to a worse cooperation score. But the
odds ratios here are very high.

# Imputing missing data

lo hago con left right porque es la que mas nos interesa imputar, para decidir qué metodo usar. Uso mice (pmm random forest, porque es factor )

```{r}

mice_imputed <- data.frame(
  original = data$left_right,
  imputed_pmm = complete(mice(data, m=1, method = "pmm", seed=123))$left_right, # We write an m=1 so that it doesn't take that long
  imputed_rf = complete(mice(data, m=1, method = "rf", seed=123))$left_right)


# Define variables, titles, and colors for the updated set of distributions
variables <- c("original", "imputed_pmm", "imputed_rf")
titles <- c("Distribution of the left_right variable", "PMM-imputed distribution", "RF-imputed distribution")
colors_fill <- c("skyblue", "#15ad4f", "#6a6ad9")
colors_border <- c("skyblue3", "#808080", "#808080")

# Transform data to long format for ggplot
mice_imputed_long <- mice_imputed %>%
  pivot_longer(all_of(variables), names_to = "method", values_to = "value")

# Facet wrap
mice_imputed_long %>%
  mutate(title = factor(method, levels = variables, labels = titles)) %>%
  ggplot(aes(x = value, fill = title)) +
  geom_bar(color = "#808080", position = "identity", alpha = 0.7, stat = "count") +  # Cambio importante aquí
  facet_wrap(~title, scales = "free_y") +
  scale_fill_manual(values = colors_fill) +
  theme_classic() +
  theme(legend.position = "none") +
  labs(title = "Comparison of Left-Right Imputation Methods",
       x = "Left-Right Categories",
       y = "Count")

```

They seem to perform almost the same. We will go with pmm.

```{r}
# Get the number of columns in the dataset
num_cols <- ncol(data)

# Define the imputation method for each column
method_vector <- rep("pmm", num_cols)  # Use "pmm" for all columns

# Identify the position of the target variable
target_variable <- "trans_docs"
target_position <- which(names(data) == target_variable)

# Do not impute the target variable
method_vector[target_position] <- ""  # Leave this position blank

# Perform imputation without modifying the target variable
imputed_data <- mice(data, method = method_vector, m = 1, seed = 123)

# Get the fully imputed dataset
final_data <- complete(imputed_data)


colSums(is.na(data))
colSums(is.na(final_data))

```
--> WE STILL HAVE NAs i don't understand why:(


To be done...

# Explanatory model

To be done...

Idea was; run a stepwise with all individual data, get back important
variables and then run a mixed model adding country level variables

### Simple logistic regression

I am using only individual level data for now

Example below can also be done with less variables to ensure readibility

```{r}
datalr <- data |> 
  # Dropping all NAs for now (glm does this automatically already)
  drop_na() |> 
  # Selecting only predictor variables
  select(-c("serialid", "country"))
# Notice df goes from 27k observations to 17k observations 

simple_logistic <- glm(trans_docs ~ ., data = datalr, family = binomial(link = "logit"))
summary(simple_logistic)
# Scaling needed? If so where it should be done?
```

No support are 1s basically and support are 0s.

From documentation: "the first level denotes failure and all others
success".

```{r}
levels(datalr$trans_docs)
# Yes = failure = 0
# No = success = 1
```

```{r}
# all the coefficients
head(coef(simple_logistic))

# for their interpretation
head(exp(coef(simple_logistic)))
# The exponential of the slope coefficient (exp(B)) tells us the factor by which odds increase if the independent variable increases by one unit?
```

```{r}
# AIC of model
simple_logistic$aic

#predicted probabilities of being a 1 (i.e. a refusal of possibility of trans doc)
predicted_probs <- simple_logistic$fitted.values
# same by running
predicted_probs <- predict(simple_logistic, type = "response")
head(predicted_probs)

# Turning them to classes using custum threshold
predicted_classes <- ifelse(predicted_probs > 0.5, "No", "Yes")
head(predicted_classes)
```

```{r}
confusionMatrix(as.factor(datalr$trans_docs), as.factor(predicted_classes))
```

```{r}
roc_obj <- roc(datalr$trans_docs, predicted_probs)

#Terrible graphs, do we have better ones?
pROC::ggroc(roc_obj)
plot(roc_obj)

coords(roc_obj, "best")

auc(datalr$trans_docs, predicted_probs)
```

## Stepwise regression

```{r}
stepAIC <- step(simple_logistic, direction = "both")
stepAIC
```

Should we use OLS instead of Stepwise?

Also we can check coherence of Stepwise results with simple logistic regression's results

## Mixed model

Random Intercept Model:

Allows the baseline level (intercept) to vary across groups. Assumes the relationship between predictors and outcome (slope) is the same for all groups

In R syntax: y ~ x + (1|group)

Example: Different schools might have different average test scores (random intercepts), but the effect of study hours on test scores is the same across all schools

Random Slope Model:

Allows the effect of a predictor (slope) to vary across groups. Can be used with or without random intercepts.

In R syntax: y ~ x + (0+x|group) for random slope only, or y ~ x + (1+x|group) for both random intercept and slope

Example: The effect of study hours on test scores might be stronger in some schools than others (random slopes)

Random intercept models account for different baselines between groups, while random slope models account for different relationships between predictors and outcomes across groups. When both random intercepts and slopes are included, you're allowing both the baseline and the effect of predictors to vary by group.

Interactions between group-level (higher-level) variables and individual-level (lower-level) variables in mixed models are called cross-level interactions.

Cross-level interactions are particularly useful in multilevel research because they help you understand how the relationship between an individual-level predictor and the outcome varies as a function of a group-level characteristic.

For example, in educational research: 1) Individual level: student characteristics (study time, prior knowledge). 2) Group level: school or classroom characteristics (class size, teaching method). 3) Cross-level interaction: Does the effect of study time on performance depend on class size?

```{r}
complete_df <- complete_df |> 
  drop_na() |> 
  select(-"serialid")

# Scaling the variables speeds up the running time. However we loose interpretation?
scaled_df <- complete_df |>
  mutate(across(where(is.numeric), scale))

glmer_model <- glmer(trans_docs ~ gender:lgbt_policy_index + gender*gender_inequality_index + religion*gdp_pc_ppp + (1 | country), data=scaled_df, family=binomial(link="logit"))

#variable1*variable2 includes both the two variables separetely and their interaction
#variable1:variable2 includes only the interaction
#+ (1|country) country is the grouping variable, means it includes different intercepts for each country

summary(glmer_model)
```

The idea is to run interactions between individual level variables and country level variables choosing pair which make sense (ex. does the effect of being female on support for trans docs depend on the gender equality index? --> did this by doing gender*gender_inequality_index)

Let's use our brain and common sense to choose the best combinations

# Predictive model

Summarize individual data to a country level (ex. percentage of
population living in rural areas by country, percentage of people from
minority x by country)

Run random forest/gradient boosting/logistic regression with
leave-one-out cross validation

## Aggregating individual data to country level

We should be builiding a dataframe with 28 rows (1 per country), but
many variables (ex, percentage of christian people by country,
percentage of very satisfied with lives people by country, percentage of
people that belong to the roma minority etc.; our target variable would
become % of people that support trans_docs by country)

Synthesizing the information from the individual respondents into country-level variables? but I don't know if this is something that models do directly.

My approach was using means for numeric variables:

```{r}
names(select(data, where(is.numeric)))

data_num <- data %>%
  group_by(country) %>%
  summarise(across(where(is.numeric), ~mean(. , na.rm = TRUE), .names = "mean_{.col}"))
str(data_num)
```

As well as for dummies:

```{r}
# searching for factor variables with two levels
dummy_names <- names(data)[sapply(data, is.factor) & sapply(data, function(x) length(levels(x)) == 2)]
dummy_names

dummy_levels <- lapply(data[dummy_names], levels)
dummy_levels

data_dummy <- data %>%
  select(country, all_of(dummy_names)) %>%
  mutate(across(all_of(dummy_names),
                ~ case_when(
                  . %in% c("0", "1") ~ as.numeric(as.character(.)),  # Converts "0"/"1" to 0/1
                  . %in% c("Yes", "No") ~ recode(., "Yes" = 1, "No" = 0),  # Converts "Yes"/"No" to 1/0
                  . %in% c("Man", "Woman") ~ recode(., "Man" = 1, "Woman" = 0),  # Converts "Man"/"Woman" to 1/0
                  TRUE ~ NA_real_  # Assigns NA to other unexpected values
                ),
                .names = "{.col}_num"))
```

I converted factors with 2 levels to numerical 0-1 so we can compute
their means.

```{r}
data_dummy <- data_dummy %>%
  group_by(country) %>%
  summarize(across(ends_with("_num"), \(x) mean(x, na.rm = TRUE)), .groups = "drop")

# substitute the "_num" suffix with a "mean_" prefix so it has the same format as the variables in data_num
data_dummy <- data_dummy %>%
  rename_with(~ paste0("mean_", str_remove(., "_num$")), ends_with("_num"))
str(data_dummy)
```

Now we can join the two datasets:

```{r}
data_aggr <- data_num %>%
  left_join(data_dummy, by = "country")
```

The next variables are not numeric nor factor with 2 levels, so they are
not included in data_aggr:

```{r}
names(data)[!sapply(data, is.numeric) &
              !(sapply(data, is.factor) & sapply(data, function(x) length(levels(x)) == 2))]
```


## Linear regression with LASSO

## Random forest

## Gradient boosting

# Brad's theory notes

Leaving this section here, it is to be deleted as we incorporate what we
need from here into the explanatory model part

#### Running a different logistic model for each country

We now have a table to test some glmer modelling on.

Following this tutorial Marga sent and applying to the test data:

<https://raffaelevacca.github.io/Intro-multilevel-with-R/>

Testing a nested dataset by country

```{r}
# Commented the below as we are probably not gonna use it

# nested.cntry <- complete_df %>% 
#   group_by(country) %>%
#   nest()
# 
# # The column nested.df$data is a list of data frames, one for each country
# class(nested.cntry$data) # type, list
# length(nested.cntry$data) # number of countries
# 
# # to unnest()
# nested.cntry %>%
#   filter(country == "AT") %>%
#   dplyr::select(country, data) %>%
#   unnest(cols = c(data))

# # Using the nested data, we now run a model for each country:

# # fit separate lm for each each element of nested.cntry$data)
# lmodels <- nested.cntry %>%
#   # Get all data frames
#   pull(data) %>%
#   # Run glm() on each via map because it's a classification model
#     # model run against all vairables for now. 
#   purrr::map(~ glm(trans_docs ~ ., 
#                    data= .x,
#                    family = "binomial"))
# 
# # show that it's a list and we can call each elements regression output. 
# class(lmodels)
# lmodels[4]
```

#### Mixed models

Fixed effects: Things that are the same across the cluster Random
effects: Things that change within the cluster

The fixed and random effects could refer to either the intercept or the
slope, as these can both vary between groups.

##### LMM equation structure in R

To run a multilevel linear model, we use the lmer() function (“Linear
Mixed Effects in R”) from the lme4 package. The syntax is similar to
regression. everything to the left of the \| indicates the effects that
should be random, and the variable to the right of the \| is the
grouping variable across which the effects should vary

*Null model* This has no slope, but random intercepts. It basically just
takes the average. It has no independent (X) variables and is the proper
naïve model.

null_model \<- lmer(Y \~ (1\|cntry), data = ess)

*Random intercept model:* --\> Only the intercept differ. The slopes are
equal for each group. We assume the same effect of X on Y for each
group. Just that the group causes the difference.

random_int_model \<- lmer(Y \~ X + (1 \| group), data=df)

*Random intercept, random slope model* --\> Now we also let the slope
vary by group. This means each group basically has it's own model. It is

random_intslope_model \<- lmer(Y \~ X + (X \| group), data=df)

For each, Y=target, X = independent vars (can be many)

##### Standard LMM Modelling Strategy

(sourced from slides here:
<https://favstats.github.io/intro_multilevel/slides/#54>) \^ This is a
useful resource, it goes through an ESS modelling doc

Approach to multilevel model building based on Hox (2010)

1/ Null Model (Random Intercept only) 2/ Add independent Level 1
variables 3/ Add independent Level 2 variables 4/ Add random slopes 5/
(Cross-level) interactions

Each step, check whether your model is significantly improved compared
to the previous one.

##### Basic LMM testing with toy data

First, null model:

```{r}
m_null <- glmer(trans_docs ~ (1|country),
               data = complete_df,
               family = "binomial",
               control = glmerControl(optimizer = "bobyqa"),
               nAGQ = 10)
summary(m_null)
```

To come back and reinterpret... don't really know at this stage.

Test flexplot and broom.mixed usage:

```{r}
# #devtools::install_github("dustinfife/flexplot")
# library(flexplot)
```

Here it has some examples of code and output for saved logistic model
fits

```{r}
# # don't think flexplot will be super useful as we have so many categorical variables
# flexplot::logistic_fit
# flexplot::mixed_logistic
# flexplot::visualize(m_null)
# 
# # broom.mixed is used to tidy up the stats outputs into a tibble
# broom.mixed::tidy(m_null) # summary output in tibble
# broom.mixed::glance(m_null) # model performance summary

```

Random effects model

-   Including individual level variables only with country:

```{r}
n_randeffect <- glmer(trans_docs ~ 
                        gender + age + I(age^2) + life_sat + religion + social_class + 
                        (1|country),
               data = complete_df,
               family = "binomial",
               control = glmerControl(optimizer = "bobyqa"),
               nAGQ = 10)
```

This suggests the data needs to be rescaled, to check which variables
are the issue:

```{r}
# check for nearzero variance, if so those could be removed
nearZeroVar(complete_df, saveMetrics = TRUE)
# see no issues. So all variables stay.

# will recode the numeric variables I selected, which is only age
scaled_df <- complete_df |>
  mutate(across(where(is.numeric), scale))
```

Re check the random effects model with scaled data:

```{r}
n_randeffect <- glmer(trans_docs ~
                        gender + age + I(age^2) + life_sat + (1|country),
               data = scaled_df,
               family = "binomial",
               control = glmerControl(optimizer = "bobyqa"),
               nAGQ = 10)



summary(n_randeffect)
```

Can we interpret this...

*Example Random effects models:* m \<- glmer(remission \~ IL6 + CRP +
CancerStage + LengthofStay + Experience + (1 \| DID), data = hdp, family
= binomial, control = glmerControl(optimizer = "bobyqa"), nAGQ = 10)

*Example from last year code* glm_model_4 \<- glmer(binary_qc19 \~
male + d11 + I(d11\^2) + political_ideology + Religion_cat +
sd1_7_factor + d60_ordinal + qc15_1_ordinal + prop_gndr_bin +
prop_dis_wide + Unemployment + (1 \| country_name), data = Data, family
= binomial, control = glmerControl(optimizer = "bobyqa", optCtrl =
list(maxfun = 100000)))

*Potentially useful package for visualising and interpreting linear
mixed models:* Flexplot -\> <https://github.com/dustinfife/flexplot>
Functions to quickly visualise LMM models and compare their performance.

broom.mixed The function broom.mixed::tidy() gives us all model
parameters (random and fixed).

*Useful calculations:* - ICC (intra cluster correlation. How alike each
of the observations within each group are) - ANOVA for model comparison:
anova(null_model, lvl1_preds_model, lvl2_preds_model, rs_preds_model)
