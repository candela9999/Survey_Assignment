---
title: "Survey II Assignment"
author: "..."
output: 
  html_document:
    toc: true
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Loading libraries

```{r, message = FALSE}
rm(list = ls())
library(tidyverse)
library(haven)
library(readxl)
library(xml2)
library(rvest)
library(janitor)
library(DataExplorer)
library(countrycode)
library(explore)
```

# Loading data

## Survey data

```{r}
data_raw <- read_dta("ZA7575.dta")
```

## Country-level data

### GDP per capita

Retrieved from Eurostat (<https://ec.europa.eu/eurostat/databrowser/view/tipsna40/default/table?lang=en>) for the year 2019.

```{r}
gdp_data <- read_xlsx("gdp_pc_2019.xlsx", sheet = 3, range = "A11:B39", col_names = c("country", "gdp_pc"))
str(gdp_data)
```

1)  United Kingdom is missing from this dataset as well as from a few others in Eurostat (we might have to find it somewhere else).

2)  Data needs further cleaning

3)  Reflect whether we might be better suited with other measures of GDP (GDP at PPP)

### Rural population

Retrieved from the World Bank (<https://data.worldbank.org/indicator/SP.RUR.TOTL.ZS>).

Data on the % of population living in rural areas over total population.

```{r}
rural_data <- read_xls("rural_pop.xls", sheet = 1, range = "A4:BL270")

# selecting only the relevant year
rural_data <- rural_data |> 
  select(`Country Name`, `Country Code`, `2019`) |> 
  clean_names() |> 
  rename("rural_pop_percentage" = "x2019")

# builidng a df with country names and codes for the EU-28
codelist <- countrycode::codelist |> 
  select(country.name.en, iso.name.en, un.name.en, cow.name, ecb, eurostat, iso2c, iso3c, eu28) |> 
  filter(!is.na(eu28)) 

rural_data <- rural_data |> 
  inner_join(select(codelist, iso3c), by = c("country_code" = "iso3c"))
str(rural_data)
```

### Same sex unions

Retrieved from Wikipedia (<https://en.wikipedia.org/wiki/Recognition_of_same-sex_unions_in_Europe>).

Table about status of same sex unions by country in Europe.

```{r}
# scraping the table
marriage_data <- read_html("https://en.wikipedia.org/wiki/Recognition_of_same-sex_unions_in_Europe") |>
  html_table() %>%
  .[[4]] |>
  select(Status, Country)

# cleaning the status column
marriage_data <- marriage_data |> 
  mutate(Status = str_remove(Status, "\\s*\\(.*|\\s*-.*")) |> 
  filter(!Status %in% c("Total", "Subtotal"))

# cleaning the country column
marriage_data <- marriage_data |> 
  mutate(Country = str_replace_all(Country, c("\\*" = "", "â€ " = "", "\\[.*?\\]" = ""))) |> 
  mutate(Country = trimws(Country))

# keeping only eu-28 countries 
marriage_data <- marriage_data |> 
  inner_join(select(codelist, cow.name), by = c("Country" = "cow.name"))
str(marriage_data)
```

This variable could be recoded as either ordinal, categorical (both factor) or logical.

The dataset has 32 observations instead of 28 (EU-28 countries).

```{r}
marriage_data |> 
  add_count(Country) |> 
  filter(n > 1)
```

According to this test, Croatia, Hungary, Latvia and Slovakia have two different types of status, so maybe we should cross-check with other sources?

Diego: the thing is that countries can at the same time have a constitutional ban on marriage and still have legally recognized civil unions. Thus maybe we should exclude this level from this variable as it is not exclusive. The lowest level would remain no recognition.

### Gender Equality Index

Developed by the European Institute for Gender Equality. Retrieved from <https://eige.europa.eu/gender-statistics/dgs/indicator/index__index_scores/datatable> for the year 2019.

```{r}
# cleaning the data
gequality_index <- read_xlsx("gender_equality_index_scores.xlsx", range = "A16:V44")
names(gequality_index) <- names(gequality_index) %>%
  janitor::make_clean_names() %>%
  gsub("_score$", "", .)

gequality_index <- gequality_index |>  
  rename(country_name = geographic_region_sub_domain_scores)
str(gequality_index)
```

No UK in this datset (28 rows because it is present a row about EU as a whole)

### Economist's Democracy Index

```{r}
democracy_index <- read_xlsx("EIU_democracy_index.xlsx", sheet = 4)

# the ISO codes were lowercase which impedes the join
democracy_index$geo <- toupper(democracy_index$geo)

# filter for 2019 and EU28 countries
democracy_index <- democracy_index |> 
  filter(time == 2019) |> 
  inner_join((select(codelist, iso3c)), by = c("geo" = "iso3c"))

# clean var names
names(democracy_index) <- names(democracy_index) %>%
  janitor::make_clean_names() %>%
  gsub("_eiu$", "", .)

democracy_index <- democracy_index |> 
  rename(country_code = geo,
         country_name = name,
         year = time)

str(democracy_index)
```

In both of these tables (Gender Equality and Democracy indexes) there
are more indicators apart from the overall indexes, we have to decide if
we think they're useful or if we can discard some/all of them.

# Data cleaning

## Selecting relevant variables in the survey data

We are discarding all variables that relate to trade and globalization as deemed not relevant for our analysis `qa`. We are also discarding variales related to energy policies `qb`.

We have also not considered questions specifically about Roma ex `qc8` and `qc14` and `qc16`

Some of the doubts we had:

AGE

```{r}
age_df <- data_raw |> summarise(mean = mean(qc19), .by = d11)
ggplot(age_df, aes(x = d11, y = mean)) + geom_point()
```
As relationship seems pretty linear we are going to use the continuous variable for age and there seems to be a clear group (1to4) which is the same used in the variable with 3 categories left, center and right so we will use the 3-categories variable

POLITICAL OPINIONS

```{r}
political_df <- data_raw |> summarise(mean = mean(qc19), .by = d1)
ggplot(political_df, aes(x = d1, y = mean)) + geom_point() + xlim(1,10)
```

For political opinions it seems that the relationship is less linear so we will work on the 5 categories cod

NATIONALITY

There is no easy way to create an immigrant dummy by checking whether someone does not have the nationality of the country in which he is being interviewed for the survey. So we are just going to use `q1_29` as a dummy for whether someone owns a non-EU nationality

POLITICAL INTEREST

Using only `polintr` as a summary of the whole `d71` question about how strong is your interest in politics in various domains

EXPERIENCED DISCRIMINATION

For the questions about whether you have experienced discrimination `qc2_` I am keeping only `qc2_15` which is a binary on whether you have experienced any discrimination or not and I am not keeping the other categories that allowed us to understand if you had experienced discrimination on the basis of a particular motive. We can probably assume that if a person is a part of a specific minority (info from `sd2`) and is being discriminated is because of being part of that minority (at least in most cases), therefore it felt like information we already had (and which we can easily put in our regression using interaction effects)

PERCIEVED DISCRIMINATION in country

This is a question (`qc1`) about how widespread you perceived discrimination is in your country. It is a rather peculiar question because it asks indiviudals for perception at the country level. I think it might be more useful (by aggregating results by country) to use it to build a country level indicator of perceived discrimination against certain minorities that are of our interest rather than use it as an individual level variable. So I will keep them out of the dataset for now

For the same reason I am also discarding `qc4` that asks whether in your country you feel like candidates with certain characteristics would be at a disadvantage in the recruitment process. It still basically asks about perceived discrimination at the country level.

And the same reasoning also applies to `qc7` which asks if efforts towards reducing discrimination are effective in your country.

HOW DISCRIMINATORY ARE YOU score

I use `qc12` and `qc13` to build a score from 1 to 10 of how discriminatory are you against certain minorities. I am building the score for each minority and then we can decide later if some are irrelevant.

Note for some categories this score is a bit stupid (ex. voting for whether you would feel uncomfortable if your child was in a love relationship with a old person would give you a high racist score against old people, this is an example of some of the categories for which it is worth excluding the index)

We can also further aggregate to obtain just one score (or obtain religious/ethnic score etc.). 

Option also to discard them all (anti lgbtqi sentiment is also captured in the next index built from `qc15`)

`qc6` also asks about discriminatory behaviors, but is about elected public official, it does not ask about a situation that impacts you personally. It also uses different categories for minorities therefore I prefer to use `qc12` and `qc13` rather than `qc6`

SUPPORTIVE OF LGBTQ RIGHTS INDEX

Using `qc15` we can again build an index for how supportive of lgbtq rights a person is. 

I again choose to take the mean across the different answers but we could also use median/mode if we think is better

If we feel each or some answers are particularly useful (given they are closely related with our target variable) we can also use them separately 

We could also use `qc18` to try to capture anti lgbtq sentiment, but I preferred `qc15` as it seemed more straightforward (I therfore deleted `qc18`, but we can put it back if useful)

OTHERS

`qc11` is a strange question feels useless to me, I removed it for now but we can think about it

I also removed `qc9` as I don't really know what to do with it and `qc17`

```{r}
data <- data_raw |> 
  select(serialid, # unique identifier
         isocntry, # 2 digit country code
         d11, # age variables
         q1_29, # nationality of interviewee. options given: EU28+Other+DK, using only other = outside of EU
         d70, #life satisfaction
         polintr, # political interest index (summarizes d71 questions)
         starts_with("sd1"), # friends that are minority groups
         starts_with("sd2"), # are you part of a minority
         sd3, # religion
         qc2_15, # experienced discrimination yourself
         qc3, # where discrimination took place
         starts_with("qc5"), # actions against discrimination
         qc10, # how would you report discrimination
         starts_with("qc12"), # feelings about colleagues being minority
         starts_with("qc13"), # feelings about kid being in a relationship with minority
         starts_with("qc15"), # opinions about lgbtqi 
         qc19, # target variable transgender
         qc20, # non-binary genders in documents
         d1r1, # political ideology
         d7, d7r1, d7r2, d7r3, # marital status
         d10, # gender binary
         starts_with("d8"), # eduaction 
         starts_with("d15"), # occupation
         d25, # rural vs urban
         starts_with("d43"), # phones availiabilty
         d60, # financial stress (paying bills)
         starts_with("d62"), # internet use
         netuse, # internet index
         d63, # social class
         starts_with("d72"), # my voice counts
         # nuts, nutslvl, # region in which interview is carried out?
         # cntry_de useful?
         # starts_with("eu"), # groups by eu/eurozone memberships
         # starts_with("w"), # weights for what?
  )

paradata <- data_raw |> 
  select(serialid, # to match it with the other data
         p2, p3, p3r, p4, p5, # paradata)
  )
```

Removing some of the previously selected variables

`sd2_7` to `sd2_10`: these are possible answer deemed irrelevant to the question about yourself being part of the following minorities:
`sd2_7` other minorities (I don't know what other relevant minorities could be there), 
`sd2_8` not part of minorities (can be deducted from the rest), 
`sd2_9` refusal to respond, 
`sd2_10` DK answers
`sd2t` summary binary variable for being part of any minority (we are going to keep the more specific one)

I also remove `qc12_nr` as I prefer to work on the full variable instead of the recoded version with less categories. Same for `qc13'
  
```{r}
data <- data |> 
  # Keep in mind that sd2t does not have NAs so we might want to use that instead of the more specific ones
  select(-c(sd2_7, sd2_8, sd2_9, sd2_10, sd2t)) |> 
  select(-(starts_with("qc12") & ends_with("r"))) |> 
  select(-(starts_with("qc13") & ends_with("r"))) |> 
  select(-(starts_with("qc18") & ends_with("r")))
```


## Check overall data quality

```{r}
explore_tbl(data)
plot_intro(data)
```

All columns are numeric columns, the only one which is not is `isocntry`

```{r}
data |> 
  select(where(~ !is.numeric(.)))
```

Most columns do not have explicit NAs

```{r}
plot_missing(data)
names(which(colSums(is.na(data)) > 0))
```

Exploiting the fact that the .dta files has attributes (labels) for all its columns.

If we search for `attr(colname, "label")` you get back the original long name of the variable 

If we instead search for `attr(colname, "labels")` you get back all the possible encoding levels of the variable (ex.1,2,3,4 etc.) and by doing `names(attr(colname, "labels"))` you get back the actual meaning of those numbers (ex. 1 = "Yes", 2 = "No", etc.)

```{r}
# Extracting all the full names of the columns
variable_names <- tibble(
  var_code = names(data),
  var_full_name = sapply(data, function(col) attr(col, "label")))
variable_names
```

These long names df might be useful to rename the variables systematically all together. Remember in case we filter out variables after this code chunk and in case we use this df to rename variables that there might be disalignments. 

Will now look into the labels for the different levels that our factor variables can take:

```{r}
attr(data$d11r1, "labels")
names(attr(data$d11r1, "labels"))
tibble(name_labels = names(attr(data$d11r1, "labels")),
       labels = attr(data$d11r1, "labels"))

# Create a list of tibbles containing the labels and their associated name for each variable
list_label_tibbles <- 
  #Applies a function across all columns of a df and returns results as a list
  lapply(names(data), function(col_name) {
    labels <- attr(data[[col_name]], "labels")  # Extract labels
    name_labels <- names(labels)  # Extract label names
    # Create tibble with the extracted data only if labels exist
    if (!is.null(labels)) {
      tibble(name_labels = name_labels, labels = labels)} 
    else {NULL}  # Returns a NULL element for columns without labels
  })

# Giving to each element of the list as name the name of the variable
list_label_tibbles <- setNames(list_label_tibbles, names(data))

# For example
list_label_tibbles$d11r1
```

Right column is what it appears in our data (as a number). Left column is the label that we must assign to that number when we factorize

## Start cleaning

```{r}
# Recoding together Germany East and West because we are running analysis at the country level
unique(data$isocntry)
data <- data |> 
  mutate(isocntry = case_when(
    isocntry %in% c("DE-W", "DE-E") ~ "DE",
    TRUE ~ isocntry))
# We might want to join the full name of the countries using the codelist df
```

Separating variables for which I can use the attribute labels to factorize them and the variables for which this strategy cannot be used

```{r}
data <- data |> 
  rename(friends_trans = sd1_7)

non_factor_variables <- c("serialid", "tnscntry", "isocntry", "d11", "q1_29", 
                          names(data)[startsWith(names(data), "sd1_")],
                          names(data)[startsWith(names(data), "sd2_")],
                          names(data)[startsWith(names(data), "qc5_")],
                          names(data)[startsWith(names(data), "qc12_")],
                          names(data)[startsWith(names(data), "qc13_")],
                          names(data)[startsWith(names(data), "qc15_")],
                          "d8", "opls")
factor_variables <- setdiff(names(data), non_factor_variables)
```

```{r}
# Converting them to factors and assign them their labels automatically
data <- data |> 
  mutate(across(all_of(factor_variables), labelled::to_factor))

# Turning DK into NAs for all the factor variables
data <- data |> 
  mutate(across(all_of(factor_variables), ~ fct_na_level_to_value(., extra_levels = "DK")))

# Converting to numeric the variables that should be numeric
# They are already numeric but they carry with them some labels as well that only confuse us, by doing this I remove the labels
data <- data |> 
  mutate(d11 = as.numeric(d11),
         d8 = as.numeric(d8))

# Converting q1_29 to factor without assigning labels (1 if non-Eu nationality, 0 if EU nationality)
# Same for sd2_
data <- data |> 
  mutate(nonEU_national = as.factor(q1_29),
         across(starts_with("sd2_"), ~ as.factor(.x))) |> 
  select(-q1_29)
```

```{r}
# Creating a variable that counts the number of different minority groups a person has acquaintances with
data <- data |>  
  mutate(across(starts_with("sd1"), ~ if_else(.x == 1, 1, 0))) |> 
  mutate(friends_minorities = sd1_1+sd1_2+sd1_3+sd1_4+sd1_5+sd1_6+sd1_8) |> 
  mutate(friends_minorities = as.factor(friends_minorities)) |> 
  relocate(friends_minorities, .before="sd1_1") |> 
  select(-starts_with("sd1"))

# Creating a variable that counts the number of actions against discrimination that you have taken in the last year
data <- data |>  
  mutate(across(starts_with("qc5"), ~ if_else(.x == 1, 1, 0))) |> 
  mutate(n_actions_against_discri = qc5_1+qc5_2+qc5_3+qc5_4) |> 
  mutate(n_actions_against_discri = as.factor(n_actions_against_discri)) |> 
  relocate(n_actions_against_discri, .after="qc3") |> 
  select(-starts_with("qc5"))
```

```{r}
# Building a discriminatory score
data <- data |> 
  # Coding as NAs it depends and DK
  mutate(across(starts_with("qc12"), ~ if_else(.x >= 12, NA, .x))) |> 
  mutate(across(starts_with("qc13"), ~ if_else(.x >= 12, NA, .x))) |> 
  # Coding as 5 responses = indifferent
  mutate(across(starts_with("qc12"), ~ if_else(.x == 11, 5, .x))) |> 
  mutate(across(starts_with("qc13"), ~ if_else(.x == 11, 5, .x))) |> 
  # Modifying such that higher is more discriminatory
  mutate(roma_discri = 11 - rowMeans(cbind(qc12_1, qc13_1), na.rm = TRUE),
         black_discri = 11 - rowMeans(cbind(qc12_2, qc13_2), na.rm = TRUE),
         asian_discri = 11 - rowMeans(cbind(qc12_3, qc13_3), na.rm = TRUE),
         white_discri = 11 - rowMeans(cbind(qc12_4, qc13_4), na.rm = TRUE),
         jewish_discri = 11 - rowMeans(cbind(qc12_5, qc13_5), na.rm = TRUE),
         muslim_discri = 11 - rowMeans(cbind(qc12_6, qc13_6), na.rm = TRUE),
         buddihst_discri = 11 - rowMeans(cbind(qc12_7, qc13_7), na.rm = TRUE),
         christian_discri = 11 - rowMeans(cbind(qc12_8, qc13_8), na.rm = TRUE),
         atheist_discri = 11 - rowMeans(cbind(qc12_9, qc13_9), na.rm = TRUE),
         lgb_discri = 11 - rowMeans(cbind(qc12_10, qc13_10), na.rm = TRUE),
         trans_discri = 11 - rowMeans(cbind(qc12_11, qc13_11), na.rm = TRUE),
         intersex_discri = 11 - rowMeans(cbind(qc12_12, qc13_12), na.rm = TRUE),
         disability_discri = 11 - rowMeans(cbind(qc12_13, qc13_13), na.rm = TRUE),
         young_discri = 11 - rowMeans(cbind(qc12_14, qc13_14), na.rm = TRUE),
         old_discri = 11 - rowMeans(cbind(qc12_15, qc13_15), na.rm = TRUE)) |> 
  select(-starts_with("qc12")) |> 
  select(-starts_with("qc13"))
# Young and old can probably be discarded, maybe religious can be aggregated
```

```{r}
# Supportive of lbtq rights index
data <- data |> 
  mutate(across(starts_with("qc15"), ~ if_else(.x == 5, NA, .x))) |>
  # Scale of 1 to 4, 1 = supportive, 4 = homophobic
  mutate(antilgbtq_rights = round(rowMeans(cbind(qc15_1, qc15_2, qc15_3), na.rm = TRUE), 2)) |> 
  select(-starts_with("qc15"))
```


Not sure what to do with qc9









We should be checking whether there are other levels for different variables that need special treatments (such as refuse to respond, should we turn those into NAs?). We can do this by looking at the summary below

First let's change the name and try to clean them to get to significant names

```{r}
# colnames(data) <- variable_names$var_full_name
# 
# data <- data |> 
#   clean_names()
```



So this is our situation so far:

```{r}
head(data)
summary(data)
plot_missing(data)
```


# Identify key socio-demogrpahic variables

From exploration of the codebook and dataframe:

*Target variable:* \* qc19 "Do you think that transgender persons should
be able to change their civil documents to match their inner gender
identity?"

Survey ID variables: - studyno1 to survey vars, all to be removed.

Respondent information -\> questions starting with "D" (D1-D77) -
political views, living situation, gender, education, occupation,
household characteristics, class

Key socioeconomic variables:

-   d1 - political ideology, left to right

-   d10 - Gender

-   d11 - Age exact

    -   Alternatives: d11r1 age recoded 4 cats, d11r2 age recoded 6
        cats, d11r3 age recoded 7 cats

-   d8 - Education, how old were you when you stopped full time
    education (Student = 00; No education = 01; refusal = 98; DK = 99

    -   d8r1 -\> 11 category recode

    -   d8r2 -\> 5 category recode s

-   d3 - religion

-   d25 - region lived in (1=rural, 2=small/medium town, 3=large town,
    4=DK)

-   d70 - life satisfaction: - 1 = very satisfied, 2= fairly, 3=not
    very, 4 = not at all, 5 = DK

-   D63 - class (working to higher, 1;5 then 6-9 no resp)

Uncertain variables, marital status (d7) /hh arrangement (d40)
/occupation (d15) / internet use (d60) Also the "sd" prefix variables..
these are about contact with different groups of discriminated people?

Paradata information -\> questions starting with "P" Paradata: -\>
P1-P10, date, time, length of interview, people present during
interview, respondent cooperation, location vars, interviewer number.

Select and rename these key variables:

```{r}
# individuals_df <- data_raw |> 
#   
#   #use select function and rename all the in scope variables 
#   select(
#       uniqid, 
#       isocntry,
#       countryid,
#       country_names,
#         
#     
#       target_var = qc19,
#       
#     # socioeconomic variables for individuals 
#       gender = d10,
#       age = d11,
#       age_4cat = d11r1,
#       age_6cat = d11r2,
#       age_7cat = d11r3,
#       polit_ideology = d1,
#       educ_5cat = d8r2, # all the education vars have low cutoffs 
#       educ_11cat = d8r1,
#       lifesat = d70,
#       religion = sd3, 
#       class = d63,
#       occ_group_recode = d15a_r2, # the occupation vars are maybe not needed too
#       financialstress = d60, #difficulty paying bills
#       polintr, # no need to rename political interest var
#       
#     # paradata variables   
#       int_date = p1,
#       int_time = p2,
#       int_length = p3r, #using recoded var instead of base p3 
#       int_ppl_present = p4,
#       int_resp_coop = p5,
#       int_location = p6, # this may be a repeat of locality variable in survey. Useful maybe to consolidate data
#       #p7 not useful, location, no data for p8-11
#       
#       #p13 is language of interview. Probably not useful? 
#       )

```

## Remove unwanted variables

The approach above may be best.. but I did start this first by deleting
variables by process of elimination. Maybe good to justify some
decisions, but I'm not sure it matters either way.

-   we do need to decide on some of the attitudinal questions if they
    are relevant enough to include. I haven't looked at all enough in
    detail.

Variable groups I suggest removing: - gen1:gen6 -\> generation
variables, offer no more info than age - nationality variables -\> would
be easier and more accurate to join an overall % of immigration variable
if we want this data. - d71, -\> the three variables are summarised in
the `polintr` variable.

```{r}
id_vars <- c("studyno1", "studyno2", "doi", "version", "edition", "survey", "caseid", "uniqid", "serialid", "tnscntry", "country")
# remove ID vars
clean1 <- data_raw |> 
  select(-any_of(id_vars))

#remove nationality variable (q1). Later, if we decide we need an immigration variable, we can impute national level data.  
clean1 <- clean1 |> 
  select(-any_of(starts_with("q1")))

# remove generation variable, too similar to age
clean1 <- clean1 |> 
  select(-any_of(starts_with("gen")))

# remove additional paradata
# clean1 <- clean1 |> 
#   select(-any_of(starts_with("p7", "p13")))

```

To discuss re: cleaning. But I think also remove all these - qa set
(from qa1 to qa20) \* on trade, globalisation, eu business

-   qb set (from qb1 to qb9) \* on energy policy and EU priorities

Do we delete all these or are we expected to do some sort of
unsupervised learning or similar to consider their attitudes? I think
not.. There is questions about priority for business

Checking how many more variables it removes. It would be 159 removed.

```{r}
data_raw |> 
  select(any_of(starts_with(c("qa", "qb")))) |> 
  ncol()
```

Removing from my test data, this still has 409 variables though.

```{r}
clean1 <- clean1 |> 
  select(-any_of(starts_with(c("qa", "qb"))))

```

## Clean respondents personal data

I think some recoding or factorising may be necessary.

Note: There are lots of haven labelled columns.. it would be quite easy
to write a function to extract the label names to a new column? This
could be easier for when we want to investigate new variables?

```{r}

```

### Impute actual NA values

As these are inconsistent between each variable, I guess we need to
override and decide if we then impute the NA values.

Clean the education variable. Currently we have: d8 - Education, how old
were you when you stopped full time education (Student = 00; No
education = 01; refusal = 98; DK = 99 - d8r1 -\> 11 category recode -
d8r2 -\> 5 category recode

Clean the

```{r}
table(data_raw$d8, data_raw$d8r2)

# First, recode the d8 values that are given as NA or student/no education
clean1 |> 
  mutate(educ = if_else(d8 %in% c(0, 1, 98, 99), NA, d8))

# if d8 = 0, they are a current student. 

```

### Analysis of missing values.

Marga discussed the importance of understanding missing values. I think
this will be an important section where we also model what type of
people are more/less likely to not respond. It's a sort of robustness
check to see how much we can trust the models. Or if specific
demographics of people are less likely to respond, then we may trust it
less.

E.g. if men/religious people are less likely to respond, it could be an
issue. Ideally we would test the representativeness of our respondents
to the questions about transgender discrimination and the overall
populations.

```{r}
#plot_missing()
summary(data_raw$d11)
# returns nothing now because of NA values are all hard coded as mixed values e.g. some are 7, 98, 12. We probably need to standardise, section above maybe
  
```

## Descriptive data analysis and checks to start

Run comparisons by country to compare ages, gender distribution, Number
of respondents per country

```{r}
# number of respondents 
```

## Testing replication of the initial plot:

-   basic version only.

```{r}

```

-   we could also recreate without any NA values to see if it makes the
    plot just seem visually more even to start?

## Modelling

Some initial thoughts:

a)  modelling the target variables
    -   base model -\> using linear mixed model to analyse individual
        and country level differences

    -   model including paradata -\> see if these impacted outcomes too

b\. modelling differences in non-response?

-   I feel like Marga mentioned this? we would need to just create a
    dummy variable for NA response to the target variable question. This
    is our secondary model target variable. I guess this could be a
    classification model? for discussion but also more thoughts in my
    missing data note above...
