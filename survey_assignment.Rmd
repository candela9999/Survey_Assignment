---
title: "Survey II Assignment"
author: "..."
output: 
  html_document:
    toc: true
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Loading libraries

```{r, message = FALSE}
rm(list = ls())
library(tidyverse)
library(haven)
library(readxl)
library(xml2)
library(rvest)
library(janitor)
library(DataExplorer)
library(countrycode)
library(explore)
library(lme4)
library(lmerTest)
library(broom.mixed)
library(ggplot2)
library(dplyr)
library(scales)
library(tidyr)
library(kableExtra)
library(gmodels)
```

# Loading data

## Survey data

```{r}
data_raw <- read_dta("ZA7575.dta")
```

## Country-level data

This is for joins:
```{r}
# builidng a df with country names and codes for the EU-28
codelist <- countrycode::codelist |> 
  select(country.name.en, iso.name.en, un.name.en, cow.name, ecb, eurostat, iso2c, iso3c, eu28) |> 
  filter(!is.na(eu28)) 
```

### GDP per capita, PPP (constant 2021 international $)

Retrieved from the World Bank (<https://data.worldbank.org/indicator/NY.GDP.PCAP.PP.KD>) for the year 2019.

```{r}
gdp_data <- read_csv("gdp_pc_ppp_2021.csv", skip = 4)

head(gdp_data)

gdp_data <- gdp_data |> 
  select(`Country Name`, `Country Code`, `2019`)


gdp_data <- gdp_data |> 
  rename(country_name = `Country Name`,
         country_code = `Country Code`,
         gdp_pc_ppp = `2019`)

gdp_data <- gdp_data |> 
inner_join(select(codelist, iso3c), by = c("country_code" = "iso3c"))

str(gdp_data)
```

We now have 28 observations including the UK.

### Rural population

Retrieved from the World Bank
(<https://data.worldbank.org/indicator/SP.RUR.TOTL.ZS>).

Data on the % of population living in rural areas over total population.

```{r}
rural_data <- read_xls("rural_pop.xls", sheet = 1, range = "A4:BL270")
head(rural_data)

# selecting only the relevant year
rural_data <- rural_data |> 
  select(`Country Name`, `Country Code`, `2019`) |> 
  clean_names() |> 
  rename("rural_pop_percentage" = "x2019")

rural_data <- rural_data |> 
  inner_join(select(codelist, iso3c), by = c("country_code" = "iso3c"))

str(rural_data)
```

### Same sex unions

Retrieved from Wikipedia
(<https://en.wikipedia.org/wiki/Recognition_of_same-sex_unions_in_Europe>).

Table about status of same sex unions by country in Europe.

```{r}
# scraping the table
marriage_data <- read_html("https://en.wikipedia.org/wiki/Recognition_of_same-sex_unions_in_Europe") |>
  html_table() %>%
  .[[4]] |>
  select(Status, Country)

# cleaning the status column
marriage_data <- marriage_data |> 
  mutate(Status = str_remove(Status, "\\s*\\(.*|\\s*-.*")) |> 
  filter(!Status %in% c("Total", "Subtotal"))

# cleaning the country column
marriage_data <- marriage_data |> 
  mutate(Country = str_replace_all(Country, c("\\*" = "", "†" = "", "\\[.*?\\]" = ""))) |> 
  mutate(Country = trimws(Country))

# keeping only eu-28 countries 
marriage_data <- marriage_data |> 
  inner_join(select(codelist, cow.name), by = c("Country" = "cow.name"))

str(marriage_data)
```

This variable could be recoded as either ordinal, categorical (both factor) or logical.

The dataset has 32 observations instead of 28 (EU-28 countries).

```{r}
marriage_data |> 
  add_count(Country) |> 
  filter(n > 1)
```

According to this test, Croatia, Hungary, Latvia and Slovakia have two
different types of status, so maybe we should cross-check with other
sources?

Diego: the thing is that countries can at the same time have a
constitutional ban on marriage and still have legally recognized civil
unions. Thus maybe we should exclude this level from this variable as it
is not exclusive. The lowest level would remain no recognition.

+Irene: I guess we need to decide whether we think it is more important/representative of a country to have civil unions for same-sex couples or a constitutional ban on same-sex marriage (this feels pretty strong tbh). It depends also on how we want to recode this.



//////////

The table is up to date, so I had to check (on Wikipedia honestly) what year each of those items was actually legalized and I got to this:
-----------------------------same sex marriage-----------------------------
Greece: civil unions since 2015, marriage since 2024
Estonia: civil unions since 2016, marriage since 2024
Slovenia: civil unions since 2017, marriage since 2022
United Kingdom: marriage since 2014 in England, Scotland and Wales, and since 2020 in Northern Ireland. Civil unions since 2005
---------------------------------civil unions-----------------------------------
Latvia: civil unions since 2024, the Constitution prohibits the recognition of same sex marriage since 2006.

```{r}
marriage_data <- marriage_data |> 
  mutate(Status = case_when(
    Country == "Greece" ~ "Civil Unions",
    Country == "Estonia" ~ "Civil Unions",
    Country == "Slovenia" ~ "Civil Unions",
    Country == "United Kingdom" ~ "Civil Unions" ,  # I understand that same-sex marriage wasn't legal in the UK until it was legalised in all of its territories, but this can be discussed
    Country == "Latvia" & Status == "Civil unions" ~ "No recognition", # only mutate one of the rows that Latvia is in
    # Latvia had no recognition prior to 2024, but it has a constitutional ban on marriage, which is a category that we found alongside others in some observations, so we'll keep two rows for Latvia for now
    TRUE ~ Status
  ))

marriage_data |> filter(Country %in% c("Latvia", "Greece", "Estonia", "Slovenia", "United Kingdom"))
```


I also found this LGBT rights index on Our World in Data (<https://ourworldindata.org/grapher/lgbt-rights-index>) which captures whether LGBT+ people enjoy the same rights as cisgender people combining information on 18 different policies. It includes the legal status of same-sex marriage so we might keep only one of these.

```{r}
lgbt_rights_index <- read.csv("lgbt-rights-index.csv")

lgbt_rights_index <- lgbt_rights_index |> 
  filter(Year == 2019) |> 
  inner_join(select(codelist, iso3c), by = c("Code" = "iso3c")) |> 
  select(-Year) # all observations are from 2019

str(lgbt_rights_index)
```


### Gender related tables

Gender Development and Gender Inequality indexes, developed by the United Nations Development. Retrieved from <https://hdr.undp.org/data-center/documentation-and-downloads> for the year 2019.

```{r}
gender_index <- read_xlsx("UNDP_gender_indexes.xlsx")

gender_index <- gender_index |>
  select(-dimension, -note, -year) |> # empty/useless columns
  inner_join(select(codelist, iso3c), by = c("countryIsoCode" = "iso3c"))

gender_index |> 
  distinct(country) |> 
  nrow()

str(gender_index)
```

This dataset now has 560 rows for the EU-28 countries, it has many indicators apart from the indexes values, which we will have to decide if we keep or not.


### Economist's Democracy Index

```{r}
democracy_index <- read_xlsx("EIU_democracy_index.xlsx", sheet = 4)

# the ISO codes were lowercase which impedes the join
democracy_index$geo <- toupper(democracy_index$geo)

# filter for 2019 and EU28 countries
democracy_index <- democracy_index |> 
  filter(time == 2019) |> 
  inner_join((select(codelist, iso3c)), by = c("geo" = "iso3c"))

# clean var names
names(democracy_index) <- names(democracy_index) %>%
  janitor::make_clean_names() %>%
  gsub("_eiu$", "", .)

democracy_index <- democracy_index |> 
  rename(country_code = geo,
         country_name = name,
         year = time)

str(democracy_index)
```

In both of these tables (Gender Equality and Democracy indexes) there
are more indicators apart from the overall indexes, we have to decide if
we think they're useful or if we can discard some/all of them.

# Data cleaning

## Selecting relevant variables in the survey data

We are discarding all variables that relate to trade and globalization
as deemed not relevant for our analysis `qa`. We are also discarding
variables related to energy policies `qb`.

We have also not considered questions specifically about Roma ex `qc8`
and `qc14` and `qc16`

<br>

Some of the doubts we had:

AGE

```{r}
x_df <- data_raw |> summarise(mean = mean(qc19), .by = d11)
ggplot(x_df, aes(x = d11, y = mean)) + geom_point()
```

As relationship seems pretty linear we are going to use the continuous
variable for age and there seems to be a clear group (1to4) which is the
same used in the variable with 3 categories left, center and right so we
will use the 3-categories variable

<br>

POLITICAL OPINIONS

```{r}
x_df <- data_raw |> summarise(mean = mean(qc19), .by = d1)
ggplot(x_df, aes(x = d1, y = mean)) + geom_point() + xlim(1,10)
```

For political opinions it seems that the relationship is less linear so
we will work on the 5 categories cod

<br>

MARRIAGE

```{r}
x_df <- data_raw |> summarise(mean = mean(qc19), .by = d7r1)
ggplot(x_df, aes(x = d7r1, y = mean)) + geom_point() + xlim(1,5)
```

Of all the possible combinations this one seems the best to highlight
differences in our target variable

<br>

NATIONALITY

There is no easy way to create an immigrant dummy by checking whether
someone does not have the nationality of the country in which he is
being interviewed for the survey. So we are just going to use `q1_29` as
a dummy for whether someone owns a non-EU nationality

<br>

POLITICAL INTEREST

Using only `polintr` as a summary of the whole `d71` question about how
strong is your interest in politics in various domains

<br>

EXPERIENCED DISCRIMINATION

For the questions about whether you have experienced discrimination
`qc2_` I am keeping only `qc2_15` which is a binary on whether you have
experienced any discrimination or not and I am not keeping the other
categories that allowed us to understand if you had experienced
discrimination on the basis of a particular motive. We can probably
assume that if a person is a part of a specific minority (info from
`sd2`) and is being discriminated is because of being part of that
minority (at least in most cases), therefore it felt like information we
already had (and which we can easily put in our regression using
interaction effects)

<br>

PERCIEVED DISCRIMINATION in country

This is a question (`qc1`) about how widespread you perceived
discrimination is in your country. It is a rather peculiar question
because it asks individUals for perception at the country level. I think
it might be more useful (by aggregating results by country) to use it to
build a country level indicator of perceived discrimination against
certain minorities that are of our interest rather than use it as an
individual level variable. So I will keep them out of the dataset for
now

For the same reason I am also discarding `qc4` that asks whether in your
country you feel like candidates with certain characteristics would be
at a disadvantage in the recruitment process. It still basically asks
about perceived discrimination at the country level.

And the same reasoning also applies to `qc7` which asks if efforts
towards reducing discrimination are effective in your country.

<br>

HOW DISCRIMINATORY ARE YOU score

I use `qc12` and `qc13` to build a score from 1 to 10 of how
discriminatory are you against certain minorities. I am building the
score for each minority and then we can decide later if some are
irrelevant.

Note for some categories this score is a bit stupid (ex. voting for
whether you would feel uncomfortable if your child was in a love
relationship with a old person would give you a high racist score
against old people, this is an example of some of the categories for
which it is worth excluding the index)

We can also further aggregate to obtain just one score (or obtain
religious/ethnic score etc.).

Option also to discard them all (anti lgbtqi sentiment is also captured
in the next index built from `qc15`)

`qc6` also asks about discriminatory behaviors, but is about elected
public official, it does not ask about a situation that impacts you
personally. It also uses different categories for minorities therefore I
prefer to use `qc12` and `qc13` rather than `qc6`

<br>

SUPPORTIVE OF LGBTQ RIGHTS INDEX

Using `qc15` we can again build an index for how supportive of lgbtq
rights a person is.

I again choose to take the mean across the different answers but we
could also use median/mode if we think is better

If we feel each or some answers are particularly useful (given they are
closely related with our target variable) we can also use them
separately

We could also use `qc18` to try to capture anti lgbtq sentiment, but I
preferred `qc15` as it seemed more straightforward (I therfore deleted
`qc18`, but we can put it back if useful)

<br>

MY VOICE COUNTS

I guess that people that feel alienated from society and politics might
be less likely to support lgbtq rights so I took the mean of `d72`
question which asked whether you felt like your voice mattered

<br>

OTHERS

`qc11` is a strange question feels useless to me, I removed it for now
but we can think about it

I also removed `qc9` as I don't really know what to do with it and
`qc17`

```{r}
data <- data_raw |> 
  select(serialid, # unique identifier
         isocntry, # 2 digit country code
         d11, # age variables
         q1_29, # nationality of interviewee. options given: EU28+Other+DK, using only other = outside of EU
         d70, #life satisfaction
         polintr, # political interest index (summarizes d71 questions)
         starts_with("sd1"), # friends that are minority groups
         starts_with("sd2"), # are you part of a minority
         sd3, # religion
         qc2_15, # experienced discrimination yourself
         qc3, # where discrimination took place
         starts_with("qc5"), # actions against discrimination
         qc10, # how would you report discrimination
         starts_with("qc12"), # feelings about colleagues being minority
         starts_with("qc13"), # feelings about kid being in a relationship with minority
         starts_with("qc15"), # opinions about lgbtqi 
         qc19, # target variable transgender
         qc20, # non-binary genders in documents
         d1r1, # political ideology
         d7r1, # marital status
         d10, # gender binary
         d8, # eduaction 
         d15a_r2, # current occupation (discarded previous occupation d15b)
         d25, # rural vs urban
         d43t, # phones availiabilty
         d60, # financial stress (paying bills)
         netuse, # internet index
         d63, # social class
         starts_with("d72"), # my voice counts
         # nuts, nutslvl, # region in which interview is carried out?
         # cntry_de useful?
         # starts_with("eu"), # groups by eu/eurozone memberships
         # starts_with("w"), # weights for what?
  )

paradata <- data_raw |> 
  select(serialid, # to match it with the other data
         p2, p3, p3r, p4, p5, # paradata)
  )
```

Removing some of the previously selected variables

`sd2_7` to `sd2_10`: these are possible answer deemed irrelevant to the
question about yourself being part of the following minorities: `sd2_7`
other minorities (I don't know what other relevant minorities could be
there), `sd2_8` not part of minorities (can be deducted from the rest),
`sd2_9` refusal to respond, `sd2_10` DK answers `sd2t` summary binary
variable for being part of any minority (we are going to keep the more
specific one)

I also remove `qc12_nr` as I prefer to work on the full variable instead
of the recoded version with less categories. Same for `qc13` and `qc18`

```{r}
data <- data |> 
  # Keep in mind that sd2t does not have NAs so we might want to use that instead of the more specific ones
  select(-c(sd2_7, sd2_8, sd2_9, sd2_10, sd2t)) |> 
  select(-(starts_with("qc12") & ends_with("r"))) |> 
  select(-(starts_with("qc13") & ends_with("r"))) |> 
  select(-(starts_with("qc18") & ends_with("r")))
```

## Check overall data quality

```{r}
explore_tbl(data)
plot_intro(data)
```

All columns are numeric columns, the only one which is not is `isocntry`

```{r}
data |> 
  select(where(~ !is.numeric(.)))
```

Most columns do not have explicit NAs

```{r}
plot_missing(data)
names(which(colSums(is.na(data)) > 0))
```

Exploiting the fact that the .dta files has attributes (labels) for all
its columns.

If we search for `attr(colname, "label")` you get back the original long
name of the variable

If we instead search for `attr(colname, "labels")` you get back all the
possible encoding levels of the variable (ex.1,2,3,4 etc.) and by doing
`names(attr(colname, "labels"))` you get back the actual meaning of
those numbers (ex. 1 = "Yes", 2 = "No", etc.)

```{r}
# Extracting all the full names of the columns
variable_names <- tibble(
  var_code = names(data),
  var_full_name = sapply(data, function(col) attr(col, "label")))
variable_names
```

These long names df might be useful to rename the variables
systematically all together. Remember in case we filter out variables
after this code chunk and in case we use this df to rename variables
that there might be disalignments.

Will now look into the labels for the different levels that our factor
variables can take:

```{r}
attr(data$d11r1, "labels")
names(attr(data$d11r1, "labels"))
tibble(name_labels = names(attr(data$d11r1, "labels")),
       labels = attr(data$d11r1, "labels"))

# Create a list of tibbles containing the labels and their associated name for each variable
list_label_tibbles <- 
  #Applies a function across all columns of a df and returns results as a list
  lapply(names(data), function(col_name) {
    labels <- attr(data[[col_name]], "labels")  # Extract labels
    name_labels <- names(labels)  # Extract label names
    # Create tibble with the extracted data only if labels exist
    if (!is.null(labels)) {
      tibble(name_labels = name_labels, labels = labels)} 
    else {NULL}  # Returns a NULL element for columns without labels
  })

# Giving to each element of the list as name the name of the variable
list_label_tibbles <- setNames(list_label_tibbles, names(data))

# For example
list_label_tibbles$d11r1
```

Right column is what it appears in our data (as a number). Left column
is the label that we must assign to that number when we factorize

## Start cleaning

```{r}
# Recoding together Germany East and West because we are running analysis at the country level
unique(data$isocntry)
data <- data |> 
  mutate(isocntry = case_when(
    isocntry %in% c("DE-W", "DE-E") ~ "DE",
    TRUE ~ isocntry))
# We might want to join the full name of the countries using the codelist df
```

Separating variables for which I can use the attribute labels to
factorize them and the variables for which this strategy cannot be used

```{r}
data <- data |> 
  rename(friends_trans = sd1_7)

non_factor_variables <- c("serialid", "tnscntry", "isocntry", "d11", "q1_29", 
                          names(data)[startsWith(names(data), "sd1_")],
                          names(data)[startsWith(names(data), "sd2_")],
                          names(data)[startsWith(names(data), "qc5_")],
                          names(data)[startsWith(names(data), "qc12_")],
                          names(data)[startsWith(names(data), "qc13_")],
                          names(data)[startsWith(names(data), "qc15_")],
                          names(data)[startsWith(names(data), "d72_")],
                          "d8", "opls")
factor_variables <- setdiff(names(data), non_factor_variables)
```

```{r}
# Converting them to factors and assign them their labels automatically
data <- data |> 
  mutate(across(all_of(factor_variables), labelled::to_factor))

# Turning DK into NAs for all the factor variables
data <- data |> 
  mutate(across(all_of(factor_variables), ~ fct_na_level_to_value(., extra_levels = "DK")))

# Converting to numeric the variables that should be numeric
# They are already numeric but they carry with them some labels as well that only confuse us, by doing this I remove the labels
data <- data |> 
  mutate(age = as.numeric(d11),
         years_edu = as.numeric(d8)) |> 
  # Recoding correctly d8 education variable according to unique(data_raw$d11))
  mutate(years_edu = case_when(
    years_edu %in% c(0, 99) ~ NA, # Refusal and DK as NAs
    years_edu == 97 ~ 0, # No full time education = 0
    years_edu == 98 ~ age, # still studying = age
    TRUE ~ years_edu)) |> 
  select(-c(d11, d8))

# Converting q1_29 to factor without assigning labels (1 if non-Eu nationality, 0 if EU nationality)
# Same for sd2_
data <- data |> 
  mutate(nonEU_national = as.factor(q1_29),
         across(starts_with("sd2_"), ~ as.factor(.x))) |> 
  select(-q1_29)
```

```{r}
# Creating a variable that counts the number of different minority groups a person has acquaintances with
data <- data |>  
  mutate(across(starts_with("sd1"), ~ if_else(.x == 1, 1, 0))) |> 
  mutate(friends_minorities = sd1_1+sd1_2+sd1_3+sd1_4+sd1_5+sd1_6+sd1_8) |> 
  relocate(friends_minorities, .before="sd1_1") |> 
  select(-starts_with("sd1"))

# Creating a variable that counts the number of actions against discrimination that you have taken in the last year
data <- data |>  
  mutate(across(starts_with("qc5"), ~ if_else(.x == 1, 1, 0))) |> 
  mutate(n_actions_against_discri = qc5_1+qc5_2+qc5_3+qc5_4) |> 
  relocate(n_actions_against_discri, .after="qc3") |> 
  select(-starts_with("qc5"))
```

```{r}
# Building a discriminatory score
data <- data |> 
  # Coding as NAs it depends and DK
  mutate(across(starts_with("qc12"), ~ if_else(.x >= 12, NA, .x))) |> 
  mutate(across(starts_with("qc13"), ~ if_else(.x >= 12, NA, .x))) |> 
  # Coding as 5 responses = indifferent
  mutate(across(starts_with("qc12"), ~ if_else(.x == 11, 5, .x))) |> 
  mutate(across(starts_with("qc13"), ~ if_else(.x == 11, 5, .x))) |> 
  # Modifying such that higher is more discriminatory
  mutate(roma_discri = 11 - rowMeans(cbind(qc12_1, qc13_1), na.rm = TRUE),
         black_discri = 11 - rowMeans(cbind(qc12_2, qc13_2), na.rm = TRUE),
         asian_discri = 11 - rowMeans(cbind(qc12_3, qc13_3), na.rm = TRUE),
         white_discri = 11 - rowMeans(cbind(qc12_4, qc13_4), na.rm = TRUE),
         jewish_discri = 11 - rowMeans(cbind(qc12_5, qc13_5), na.rm = TRUE),
         muslim_discri = 11 - rowMeans(cbind(qc12_6, qc13_6), na.rm = TRUE),
         buddihst_discri = 11 - rowMeans(cbind(qc12_7, qc13_7), na.rm = TRUE),
         christian_discri = 11 - rowMeans(cbind(qc12_8, qc13_8), na.rm = TRUE),
         atheist_discri = 11 - rowMeans(cbind(qc12_9, qc13_9), na.rm = TRUE),
         lgb_discri = 11 - rowMeans(cbind(qc12_10, qc13_10), na.rm = TRUE),
         trans_discri = 11 - rowMeans(cbind(qc12_11, qc13_11), na.rm = TRUE),
         intersex_discri = 11 - rowMeans(cbind(qc12_12, qc13_12), na.rm = TRUE),
         disability_discri = 11 - rowMeans(cbind(qc12_13, qc13_13), na.rm = TRUE),
         young_discri = 11 - rowMeans(cbind(qc12_14, qc13_14), na.rm = TRUE),
         old_discri = 11 - rowMeans(cbind(qc12_15, qc13_15), na.rm = TRUE)) |> 
  select(-starts_with("qc12")) |> 
  select(-starts_with("qc13"))
# Young and old can probably be discarded, maybe religious can be aggregated
```

```{r}
# Supportive of lbtq rights index
data <- data |> 
  mutate(across(starts_with("qc15"), ~ if_else(.x == 5, NA, .x))) |>
  # Scale of 1 to 4, 1 = supportive, 4 = homophobic
  mutate(antilgbtq_rights = round(rowMeans(cbind(qc15_1, qc15_2, qc15_3), na.rm = TRUE), 2)) |> 
  select(-starts_with("qc15"))
```

```{r}
# My voice counts
data <- data |> 
  mutate(across(starts_with("d72"), ~ if_else(.x > 4, NA, .x))) |>
  mutate(social_alienation = rowMeans(cbind(d72_1, d72_2), na.rm = TRUE)) |> 
  select(-starts_with("d72"))
# The higher the more people think their voice does not matter
```

<br><br>

<<<<<<< Updated upstream
SITUATION SO FAR

<<<<<<< Updated upstream
This should be our final selection of variables.

We still need to rename them appropriately and check that all the NAs are correctly encoded by looking at the summary. Below I left some comments about the things to do to finish the cleaning.

After that we can further discard some due to missingness, multicollinearity, irrelevance.

We need also to build the country level dataframe. Join all the country level data together.

Then next steps would involve imputing NAs, building the country level dataframe and then we can start with correlation, discarding variables and modelling

```{r}
# TO-DO-LIST

# friends_trans REFUSAL level - leave it like that or NAs?

# sd3 look more into that for NAs or aggregations as not all levels are printed with summary

# qc2_15 we need to adjust the labels: not mentioned=have been discriminated against; No, you haven’t been discriminated against or experienced harassment=no discrimination experienced

# qc10 look more into that for NAs or aggregations as not all levels are printed with summary

#d1r1 correctly encode NAs

#d7r1 correctly encode NAs

#d15a_r2 look more into that for NAs as not all levels are printed with summary

#d60 REFUSAL must be turned into NAs?

#d63 look more into that for NAs as not all levels are printed with summary

# and more? I think this is it
```


Recoding correclty all NAs

Now we will substitute de "Refusal" answers in the remaining variables as NAs. If the respondent refuses to answer it's equivalent to not knowing his or her answer. We exclude friends_trans because that category could be worth analyzing. 

```{r}

factor_variables <- names(data)[sapply(data, is.factor)]

data <- data %>%
  mutate(across(
    all_of(setdiff(factor_variables, "friends_trans")),  # Exclude "friends_trans"
    ~ {
      refusal_levels <- grep("REFUSAL", levels(.), value = TRUE, ignore.case = TRUE)  # Look for levels that contain "REFUSAL"
      if (length(refusal_levels) > 0) {  # If there are levels containing "REFUSAL"
        fct_recode(., NULL = refusal_levels)  # Convert in NA
      } else {
        .  # if not remain without changes
      }
    }
  ))

```


Rename columns appropriately

```{r}

data <- data |> 
  rename(
    country = isocntry,
    life_sat = d70,
    ethnic_minority = sd2_1,
    skincolor_minority = sd2_2,
    religious_minority = sd2_3,
    roma_minority = sd2_4,
    sexual_minority = sd2_5,
    disability_minority = sd2_6,
    religion = sd3,
    disc_no = qc2_15,
    disc_where = qc3,
    disc_contact = qc10,
    trans_docs = qc19,
    gender_docs = qc20,
    left_right = d1r1,
    marital_status = d7r1,
    gender = d10,
    occupation = d15a_r2,
    community = d25,
    phone_access = d43t,
    bill_issues = d60,
    internet_use = netuse,
    social_class = d63
  )

```


Adding a dummy variable for gender (I am keeping the original one in case is useful)

```{r}
data$man <- ifelse(data$gender == "Man", 1, 0)

```


Now, we will transform the variable disc_no, which was originally coded in a negative way (1 = "Not mentioned", 2 = "No, you haven’t been discriminated against"), into a positive dummy variable to make its interpretation more straightforward.

```{r}

data <- data |> 
  mutate(suffered_discr = ifelse(disc_no == "Not mentioned", 1, 0)) |> 
  select(-disc_no) 

```


Candela: I don't know if we have stepped on each other's toes at some point. I can't run the "identify key sociodemographic" chunk because it can't find clean1 (maybe we deleted it by accident?).


# checking missing data again, once refusals etc has also been dealed with
```{r}
plot_missing(data)
```

we should consider deleting disc_where

I was trying to plot the distributions of the numeric variables to see which ones are highly skewed and require a transformation to normalize them. It's plotting the discrete variables too. I always have the doubt if discrete variables can de transformed, idk if its a good practice.

```{r}

library(e1071)

# Identify numeric variables
numeric_vars <- names(data)[sapply(data, is.numeric)]

# Creating histogramas y calculating skweness
for (var in numeric_vars) {
  p <- ggplot(data, aes(x = .data[[var]])) +
    geom_histogram(binwidth = 1, fill = "blue", color = "black") +
    labs(title = paste("Histogram of", var), x = var, y = "Count") +
    theme_minimal()
  print(p)
  
  skew <- skewness(data[[var]], na.rm = TRUE)
  cat("Skewness of", var, ":", skew, "\n")
  
  # Suggest transformation if skeness is high
  if (abs(skew) > 1) {
    cat("--> Consider applying a logarithmic transformation to", var, "\n")
  }
}

```


#Exploratoy Descriptive Analysis 

--> it's just a first approach. I organized it it 3 blocks (sociodemographic variables, relations with minorities and paradata), but feel free to suggest even deleting most part of it. I guess Marga want us to go straightfoward and don't do unuseful things. I didn't spend a lot of time to make the graphics pretty and it's probably not the best way to visualize them. It is a first attempt that can be improved as we decide.


## Analysis of individual-level variables

We must keep in mind our Target variable is qc19 "Do you think that transgender persons should be able to change their civil documents to match their inner gender identity?"

(this graph could be redundant)

```{r}

data_percent <- data |> 
  group_by(trans_docs) |> 
  summarise(count = n()) |> 
  mutate(percentage = count / sum(count) * 100)

ggplot(data_percent, aes(x = trans_docs, y = percentage, fill = trans_docs)) +
  geom_bar(stat = "identity") +  
  geom_text(aes(label = sprintf("%.1f%%", percentage)),  
            vjust = -0.5, size = 4, color = "black") +  
  scale_y_continuous(labels = scales::percent_format(scale = 1)) + 
  labs(
    title = "Overall distribution of support for trans people to change \ntheir gender in civil documents",
    x = "Support for Transgender Rights",
    y = "Percentage"
  ) +
  theme_minimal() +
  theme(legend.position = "none")

```

Taking a look to our variable of interest alone, we see how the 52.7% of our sample are in favor of trans people to change their gender in their civil documents. However, there is also a significant opposition (35,3%), and a 12% who answered "Don't know". We will try to explore this distribution along the variables we consider to be most important for our analysis.

--> When we turned DK into NAs for all the factor variables, we also changed it for qc19 (now trans_docs). Idk if for the EDA we want to keep that category as "na". 

### Sociodemographic variables

--> Do we want to interpret significant relations of each combination of variables we are plotting? 

#### Gender

```{r}

data_summary <- data |> 
  count(trans_docs, gender, name = "n") |> 
  group_by(gender) |>  
  mutate(percentage = n / sum(n))  

ggplot(data_summary, aes(x = trans_docs, y = percentage, fill = gender)) +
  geom_bar(stat = "identity", position = "dodge") +  
  geom_text(aes(label = scales::percent(percentage, accuracy = 1)),  
            position = position_dodge(width = 0.9), vjust = -0.2, size = 4) +  
  scale_y_continuous(labels = percent_format()) + 
  labs(
    title = "Distribution of support by gender",
    x = "Support for trans people changing their civil documents",
    y = "Percentage within Gender",
    fill = "Gender"
  ) +
  theme_minimal()

# Crear una tabla de contingencia
contingency_table <- table(data$gender, data$trans_docs)

# Realizar la prueba de chi-cuadrado
chisq_test <- chisq.test(contingency_table)
print(chisq_test)

```
Men exhibit a lower percentage of favorable or dk responses and a higher rate of rejection compared to women. There is a statistically significant association between gender and our target variable, being women more supportive


#### Age
```{r}

ggplot(data, aes(x = trans_docs, y = age, fill = "blue")) +
  geom_boxplot() +
  theme_minimal() +
  labs(title = "Support by age",
       y = "Age",
       x = "Support")+
  theme(legend.position = "none")

#ANOVA
anova <- aov(age ~ trans_docs, data = data)
summary(anova)
```

There are significant differences between the groups defined by trans_docs.
 
#### Religiosity
We have two variables related to religiosity: religion (the religious affiliation professed by the respondent) and religious_minority (whether or not the respondent belongs to a religious minority group).

For the first one it's better to show a cross table instead of a plot, since there are a lot of categories

```{r}

CrossTable(data$religion, data$trans_docs,
           digits = 2, 
           expected = FALSE, 
           asresid = TRUE, 
           chisq = TRUE, 
           prop.chisq = FALSE, 
           format = "SPSS")

```

Out of all observations Catholic, Atheists/Agnostic, Orthodox Christians and Protestants sum up to the 81.04% of our sample, being the rest underrepresented. I believe the warning "Chi-squared approximation may be incorrect" is because of this. Consequently I don't know if we can trust the p-value.

```{r}
data_summary <- data |> 
  count(trans_docs, religious_minority, name = "n") |> 
  group_by(religious_minority) |>  
  mutate(percentage = n / sum(n))  

ggplot(data_summary, aes(x = trans_docs, y = percentage, fill = religious_minority)) +
  geom_bar(stat = "identity", position = "dodge") +  
  geom_text(aes(label = scales::percent(percentage, accuracy = 1)),  
            position = position_dodge(width = 0.9), vjust = -0.2, size = 4) +  
  scale_y_continuous(labels = percent_format()) + 
  labs(
    title = "Distribution of support by religious minority",
    x = "Support for trans people changing their civil documents",
    y = "Percentage within religious_minority",
    fill = "religious_minority"
  ) +
  theme_minimal()


```

#### Ideology

```{r}

data_summary <- data |> 
  count(trans_docs, left_right, name = "n") |> 
  group_by(left_right) |>  
  mutate(percentage = n / sum(n))  

ggplot(data_summary, aes(x = trans_docs, y = percentage, fill = left_right)) +
  geom_bar(stat = "identity", position = "dodge") +  
  geom_text(aes(label = scales::percent(percentage, accuracy = 1)),  
            position = position_dodge(width = 0.9), vjust = -0.2, size = 4) +  
  scale_y_continuous(labels = percent_format()) + 
  labs(
    title = "Distribution of support by ideology",
    x = "Support for trans people changing their civil documents",
    y = "Percentage within ideology",
    fill = "ideology"
  ) +
  theme_minimal()
```

Stronger left-wing support for trans rights. Right-wing respondents are the most divided, with high opposition levels.
Non-responses are highest among those without ideological alignment.

### Relations with people belonging to minority groups

```{r}

# Number of friends belonging to a minority group
ggplot(data, aes(x = trans_docs, y = friends_minorities, fill = trans_docs)) +
  geom_boxplot() +
  labs(
    title = "Support by number of friends of a minority group",
    x = "Support",
    y = "number of friends of a minority group"
  ) +
  theme_minimal()+
  theme(legend.position = "none")

```

The number of minority friends seems to be related to support to question 19.
The greater the number of minority friends, the greater the likelihood of supporting trans changing their documents.
Those with few minority friends are more likely to be unsupportive or to have no clear opinion.

### Having trans friends

```{r}
data_summary <- data |> 
  count(trans_docs, friends_trans, name = "n") |> 
  group_by(friends_trans) |>  
  mutate(percentage = n / sum(n))  

ggplot(data_summary, aes(x = trans_docs, y = percentage, fill = friends_trans)) +
  geom_bar(stat = "identity", position = "dodge") +  
  geom_text(aes(label = scales::percent(percentage, accuracy = 1)),  
            position = position_dodge(width = 0.9), vjust = -0.2, size = 4) +  
  scale_y_continuous(labels = percent_format()) + 
  labs(
    title = "Distribution of support by haivng trans friends",
    x = "Support for trans people changing their civil documents",
    y = "Percentage within groups",
    fill = "Has Trans Friends"
  ) +
  theme_minimal()

```

Having trans friends is associated with a higher support, while those who refuse to disclose their connections to trans people tend to oppose more. 


## Paradata

```{r}

# Extracting labels in paradata
list_label_tibbles <- lapply(names(paradata), function(col_name) {
  labels <- attr(paradata[[col_name]], "labels")  
  name_labels <- names(labels)  
  if (!is.null(labels)) {
    tibble(name_labels = name_labels, labels = labels)
  } else {
    NULL
  }
})

# Asign names to list elements
list_label_tibbles <- setNames(list_label_tibbles, names(paradata))

# Convert into factor
paradata <- paradata %>%
  mutate(across(where(~ !is.null(attr(., "labels"))), labelled::to_factor))

# Merging datasets for the analysis
merged_paradata <- merge(data, paradata, by = "serialid", all.x = TRUE)

```

Number of persons present during interview
```{r}
library(gmodels)

# Convert NA in a explicit category
merged_paradata$trans_docs <- as.character(merged_paradata$trans_docs)   
merged_paradata$trans_docs[is.na(merged_paradata$trans_docs)] <- "DK"  
merged_paradata$trans_docs <- as.factor(merged_paradata$trans_docs)  

# CrossTable
CrossTable(merged_paradata$p4, merged_paradata$trans_docs,
           digits=2, 
           expected=F, 
           asresid=T, 
           chisq=TRUE, 
           prop.chisq=F, 
           format="SPSS")

```
The table shows a significant association between the number of people present during the interview and support for transgender people to change their documents

Regarding the duration of the interview we have 2 options p3 and p3r. We will use p3r to have a simpler analysis

```{r}
#i first did the graph calculating the percentages over the total, maybe plotting column percentages is better, or maybe we dont want to plot it. i leave it just in case

# # Calculate percentages
# plot_data <- merged_paradata %>%
#   group_by(p3r, trans_docs) %>%
#   summarise(count = n(), .groups = 'drop') %>%
#   mutate(percentage = count / sum(count) * 100)
# 
# # Gráfico de barras agrupadas con porcentajes y etiquetas
# ggplot(plot_data, aes(x = factor(p3r), y = percentage, fill = trans_docs)) +
#   geom_bar(stat = "identity", position = position_dodge(width = 0.9)) +  # Barras agrupadas
#   geom_text(
#     aes(label = paste0(round(percentage, 1), "%")),  # Etiquetas de porcentaje
#     position = position_dodge(width = 0.9), vjust = -0.5, size = 3
#   ) +
#   scale_y_continuous(labels = percent_format(scale = 1), limits = c(0, 30)) +  # Eje Y en porcentaje (0% a 100%)
#   labs(
#     title = "Support by Interview Duration",
#     x = "Duration Categories",
#     y = "Percentage",
#     fill = "Response"
#   ) +
#   theme_minimal()

# CrossTable
CrossTable(merged_paradata$p3r, merged_paradata$trans_docs,
           digits=2, 
           expected=F, 
           asresid=T, 
           chisq=TRUE, 
           prop.chisq=F, 
           format="SPSS")

```
Respondent cooperation

```{r}

data_summary <- merged_paradata |> 
  count(p5, trans_docs, name = "n") |> 
  group_by(trans_docs) |>  
  mutate(percentage = n / sum(n))  

ggplot(data_summary, aes(x = p5, y = percentage, fill = trans_docs)) +
  geom_bar(stat = "identity", position = "dodge") +  
  geom_text(aes(label = scales::percent(percentage, accuracy = 1)),  
            position = position_dodge(width = 0.9), vjust = -0.2, size = 4) +  
  scale_y_continuous(labels = percent_format()) + 
  labs(
    title = "Distribution of support by Respondent cooperation",
    x = "Respondent cooperation",
    y = "Percentage within groups",
    fill = "Support"
  ) +
  theme_minimal()


# Calcular porcentajes
plot_data <- merged_paradata %>%
  group_by(p5, trans_docs) %>%
  summarise(count = n(), .groups = 'drop') %>%
  mutate(percentage = count / sum(count) * 100)

```
Respondents who engaged better in the survey were more likely to express support.

--> are we doing EDA for country level variables?

## Robustness checks for don't know response to NA variable

There are 3,280 NA responses to the target variable. To try understand if the missing values are at random, we will test the correlation between NA response and Use the DK for our target variable. 

In the descriptive analysis above, we have already seen in raw terms that NA responses were more frequent from women, older people, people who also responded NA for political ideology,

People who do not have trans friends and those who refused to respond to the friendship question had higher NA responses to the target variable.

By country, we already understand from the challenge description that the NA responses vary. This is a significant disparity. Because 

Create a binary variable for the DK 
```{r}
cntry_name <- codelist |> select(iso2c, country_name = country.name.en)
dk_target <- data |> 
  mutate(target_NA = ifelse(is.na(trans_docs), 1, 0)) |> 
  left_join(cntry_name, by = join_by(country == iso2c)) |> 
  dplyr::select(-trans_docs, -serialid, -country)

table(dk_target$target_NA)
```

Confirm DK rates by country. They vary from 1.4% in Belgium to 28.5% in Bulgaria. 

```{r}
dk_target |> 
  group_by(country_name) |> 
  summarise(count_na = sum(target_NA),
            num_resp = length(country_name),
            pct_na = count_na/num_resp*100) |> 
  ggplot(aes(x=reorder(country_name, -pct_na), y = pct_na))+
  geom_col()+
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        axis.title.x = element_blank()) +
  scale_y_continuous(labels = scales::percent_format(scale = 1)) + 
  labs(y = "Proportion of NA responses")

```

Treatment of NA variables

If all NA responses to the target are removed, this is how much the "Yes" count increases for each of our countries. We see this is not proportional.  distribution of the variable looks by country. 

Important to consider: The proportion of Yes to No support for document changes will alter when the NA's are removed too. 

```{r}

data |> 
  group_by(country) |> 
  summarise(yes_count = sum(trans_docs == "Yes", na.rm=TRUE),
            num_resp = sum(!is.na(trans_docs)),
            num_na = sum(is.na(trans_docs)),
            pct_yes_withna = yes_count / length(country)*100,
            pct_yes = yes_count/num_resp*100)|> 
  ggplot(aes(x = reorder(country, -pct_yes))) +
  geom_col(aes(y = pct_yes), fill = "red") + # First bar (pct_yes)
  geom_col(aes(y = pct_yes_withna), fill = "yellow", alpha = 0.5) + # Second bar (pct_yes_withna)
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        axis.title.x = element_blank()) +
  scale_y_continuous(labels = scales::percent_format(scale = 1),
                     limits = c(0,100)) + 
  labs(title ="Support for transgender rights to legally change documents, with and without NA's")

data |> 
  group_by(country) |> 
  summarise(no_count = sum(trans_docs == "No", na.rm=TRUE),
            num_resp = sum(!is.na(trans_docs)),
            num_na = sum(is.na(trans_docs)),
            pct_no_withna = no_count / length(country)*100,
            pct_no = no_count/num_resp*100)|> 
  ggplot(aes(x = reorder(country, pct_no))) +
  geom_col(aes(y = pct_no), fill = "blue") + # First bar (pct_yes)
  geom_col(aes(y = pct_no_withna), fill = "green", alpha = 0.5) + # Second bar (pct_yes_withna)
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        axis.title.x = element_blank()) +
  scale_y_continuous(labels = scales::percent_format(scale = 1),
                     limits = c(0,100)) + 
  labs(title ="NO votes for transgender rights to legally change documents, with and without NA's")

```


### Check correlation with DK of target
Run model to test what is correlated with DK response, use Chi-Sq for our factor variables

```{r}
dk_target |> select(where(is.numeric))
class(dk_target$antilgbtq_rights)
dk_target |> 
  select(antilgbtq_rights, target_NA) |> 
  plot_correlation()

dk_target |> 
  select(target_NA, any_of(where(is.factor(.)))) |> 
  chisq.test()

```

Model the data for DK response
First, stepwise to check most important data 

```{r}
factor_subset <- dk_target %>%
  dplyr::select(target_NA, where(is.factor)) |> 
  mutate(target_NA = factor(target_NA))

### Run cramers V for factors
library(DescTools)

target_var <- "target_NA"
factor_variables <- names(factor_subset)
factor_variables <- factor_variables[factor_variables != target_var]

cramers_v_results <- list()

for (variable in factor_variables) {
    contingency_table <- table(factor_subset[[target_var]], 
                               factor_subset[[variable]])
    cramers_v <- CramerV(contingency_table)
    cramers_v_results[[variable]] <- cramers_v
}

# Create a Tibble for Results
tibble(variable = names(cramers_v_results),
       cramers_v = unlist(cramers_v_results)) |> 
  arrange(desc(cramers_v))


```

This shows all of the factors have quite low association with the NA responses. The highest being internet use. This is a good sign that 

When we look at the 
```{r}
numeric_subset <- dk_target %>%
  dplyr::select(target_NA, where(is.numeric)) 

target_var <- "target_NA"
numeric_variables <- names(numeric_subset)[names(numeric_subset) != target_var]

cor_results <- list()

for (variable in numeric_variables) {
    correlation <- cor(numeric_subset$target_NA, 
                       numeric_subset[[variable]],
                       use = "pairwise.complete.obs")
    cor_results[[variable]] <- correlation
}

# Create a Tibble for Results
tibble(variable = names(cor_results),
       cor = unlist(cor_results)) |> 
  arrange(cor)

```

Again, this is not too much cause for concern. We only have around 10% correlations, positive and negative with the target variable. 

## Testing for relationship 
Testing if we run a logistic regression to test for important/significant variables. THis may be unnecessary as we have shown above low correlation with NA responses. 

```{r}
library(olsrr)
# library(MASS)
# first, run stepwise to determine most important 
dk_fit_null <- glm(target_NA ~ 1,
              data = dk_target, 
              family = "binomial")
dk_fit <- glm(target_NA ~ .,
              data = dk_target, 
              family = "binomial")
aic_1 <- stepAIC(dk_fit, scope = list(upper = dk_fit, 
                             lower = dk_fit_null),
        direction = "forward", k = 2) # forward based on p-value
summary(aic_1)


logistic_model <- glm(target_NA ~ country_name, 
                      data = dk_target, 
                      family = "binomial")
summary(logistic_model)

```

```{r}

```


Secondary model with Paradata

```{r}

```




# Identify key socio-demogrpahic variables

From exploration of the codebook and dataframe:

*Target variable:* \* qc19 "Do you think that transgender persons should
be able to change their civil documents to match their inner gender
identity?"

Survey ID variables: - studyno1 to survey vars, all to be removed.

Respondent information -\> questions starting with "D" (D1-D77) -
political views, living situation, gender, education, occupation,
household characteristics, class

Key socioeconomic variables:

-   d1 - political ideology, left to right

-   d10 - Gender

-   d11 - Age exact

    -   Alternatives: d11r1 age recoded 4 cats, d11r2 age recoded 6
        cats, d11r3 age recoded 7 cats

-   d8 - Education, how old were you when you stopped full time
    education (Student = 00; No education = 01; refusal = 98; DK = 99

    -   d8r1 -\> 11 category recode

    -   d8r2 -\> 5 category recode s

-   d3 - religion

-   d25 - region lived in (1=rural, 2=small/medium town, 3=large town,
    4=DK)

-   d70 - life satisfaction: - 1 = very satisfied, 2= fairly, 3=not
    very, 4 = not at all, 5 = DK

-   D63 - class (working to higher, 1;5 then 6-9 no resp)

Uncertain variables, marital status (d7) /hh arrangement (d40)
/occupation (d15) / internet use (d60) Also the "sd" prefix variables..
these are about contact with different groups of discriminated people?

Paradata information -\> questions starting with "P" Paradata: -\>
P1-P10, date, time, length of interview, people present during
interview, respondent cooperation, location vars, interviewer number.

Select and rename these key variables:

```{r}
individuals_df <- clean1 |>

  #use select function and rename all the in scope variables
  select(
      isocntry,
      # countryid,
      # country_names,


      target_var = qc19,

    # socioeconomic variables for individuals
      gender = d10,
      age = d11,
      age_4cat = d11r1,
      age_6cat = d11r2,
      age_7cat = d11r3,
      polit_ideology = d1,
      educ_5cat = d8r2, # all the education vars have low cutoffs
      educ_11cat = d8r1,
      lifesat = d70,
      religion = sd3,
      class = d63,
      occ_group_recode = d15a_r2, # the occupation vars are maybe not needed too
      financialstress = d60, #difficulty paying bills
      polintr # no need to rename political interest var

    # # paradata variables
    #   int_date = p1,
    #   int_time = p2,
    #   int_length = p3r, #using recoded var instead of base p3
    #   int_ppl_present = p4,
    #   int_resp_coop = p5,
    #   int_location = p6, # this may be a repeat of locality variable in survey. Useful maybe to consolidate data
    #   #p7 not useful, location, no data for p8-11
    # 
    #   #p13 is language of interview. Probably not useful?
      )

```

## INITIAL TESTING: Classification models for each country

Trying to see how lmm functions work with indiviudal and country level data. 

The primary package we will use is the lme4 package. 

The toy data will be the individuals_df data from above, but joined on, will be the country level indicators. I am going to ignore the UK for now just for convenience and focus on modelling. UK data should be available later 

First, create a country level table for all the data of interest: 

```{r}
country_level_data <- codelist |> 
  left_join(gdp_data, by = join_by(country.name.en == country)) |> 
  left_join(rural_data, by = join_by(iso3c == country_code)) |> 
  # left_join(marriage_data, by = join_by(country.name.en == Country)) |> # excluding the marriage data for now because it has multiple variables for the same country
  left_join(democracy_index, by = join_by(iso3c == country_code)) |> 
  left_join(gequality_index, by = join_by(country.name.en == country_name))

country_level_testdata <- country_level_data |> 
  select(iso2c, 
         gdp_pc, 
         #marriage_stat = Status, #rename
         rural_pop_percentage, 
         democracy_index, 
         overall_gender_equality_index)
```

Now set our test data. for ease, we will remove the UK from the main data then join on all others (as UK has some NA obs for gender equality index + gdp to be amended)

```{r}

complete_df <- individuals_df |> 
  filter(isocntry != "GB") |> 
  left_join(country_level_testdata, 
            by = join_by(isocntry == iso2c)) |> 
  filter(!is.na(target_var)) # remove NA for our target variable. 
  
```

We now have a table to test some glmer modelling on. 

We have table of 26,416 row table with 20 columns. This represents 27 countries. 

Following this tutorial Marga sent and applying to the test data: 

https://raffaelevacca.github.io/Intro-multilevel-with-R/

Testing a nested dataset by country
```{r}

nested.cntry <- complete_df %>% 
  group_by(isocntry) %>%
  nest()

# The column nested.df$data is a list of data frames, one for each country
class(nested.cntry$data) # type, list
length(nested.cntry$data) # number of countries

# to unnest()
nested.cntry %>%
  filter(isocntry == "AT") %>%
  dplyr::select(isocntry, data) %>%
  unnest(cols = c(data))


```

Using the nested data, we now run a model for each country:

```{r}
# fit separate lm for each each element of nested.cntry$data)
lmodels <- nested.cntry %>%
  # Get all school data frames
  pull(data) %>%
  # Run glm() on each via map because it's a classification model
    # model run against all vairables for now. 
  purrr::map(~ glm(target_var ~ ., 
                   data= .x,
                   family = "binomial"))

# show that it's a list and we can call each elements regression output. 
class(lmodels)
lmodels[4]
```


## Basics of Linear mixed models in R

Fixed effects: Things that are the same across the cluster
Random effects: Things that change within the cluster 

The fixed and random effects could refer to either the intercept or the slope, as these can both vary between groups.

### The names and structure of different LMM models in R: 

#### LMM equation structure in R

To run a multilevel linear model, we use the lmer() function (“Linear Mixed Effects in R”) from the lme4 package. The syntax is similar to regression. 
everything to the left of the | indicates the effects that should be random, and the variable to the right of the | is the grouping variable across which the effects should vary

*Null model* 
This has no slope, but random intercepts. It basically just takes the average. It has no independent (X) variables and is the proper naïve model. 

  null_model <- lmer(Y ~ (1|cntry), data = ess)


*Random intercept model:* 
--> Only the intercept differ. The slopes are equal for each group. We assume the same effect of X on Y for each group. Just that the group causes the difference. 

  random_int_model <- lmer(Y ~ X + (1 | group), data=df)

*Random intercept, random slope model* 
--> Now we also let the slope vary by group. This means each group basically has it's own model. It is 

  random_intslope_model <- lmer(Y ~ X + (X | group), data=df)

For each, Y=target, X = independent vars (can be many)

#### Standard LMM Modelling Strategy
(sourced from slides here: https://favstats.github.io/intro_multilevel/slides/#54)
^ This is a useful resource, it goes through an ESS modelling doc 

Approach to multilevel model building based on Hox (2010)

1/  Null Model (Random Intercept only)
2/ Add independent Level 1 variables
3/ Add independent Level 2 variables
4/ Add random slopes
5/ (Cross-level) interactions

Each step, check whether your model is significantly improved compared to the previous one.

### Basic LMM testing with toy data 

First, null model:
```{r}
m_null <- glmer(target_var ~ (1|isocntry),
               data = complete_df,
               family = "binomial",
               control = glmerControl(optimizer = "bobyqa"),
               nAGQ = 10)
summary(m_null)
```

To come back and reinterpret... don't really know at this stage.

Test flexplot and broom.mixed usage: 

```{r}
#devtools::install_github("dustinfife/flexplot")
library(flexplot)
```

Here it has some examples of code and output for saved logistic model fits

```{r}
# don't think flexplot will be super useful as we have so many categorical variables
flexplot::logistic_fit
flexplot::mixed_logistic
flexplot::visualize(m_null)

# broom.mixed is used to tidy up the stats outputs into a tibble
broom.mixed::tidy(m_null) # summary output in tibble
broom.mixed::glance(m_null) # model performance summary

```

Random effects model 

- Including individual level variables only with country: 

```{r}
n_randeffect <- glmer(target_var ~ 
                        gender + age + I(age^2) + lifesat + religion + class + 
                        (1|isocntry),
               data = complete_df,
               family = "binomial",
               control = glmerControl(optimizer = "bobyqa"),
               nAGQ = 10)
```
This suggests the data needs to be rescaled, to check which variables are the issue:
```{r}
library(caret)
# check for nearzero variance, if so those could be removed
nearZeroVar(complete_df, saveMetrics = TRUE)
# see no issues. So all variables stay.

# will recode the numeric variables I selected, which is only age
scaled_df <- complete_df |> 
  mutate(across(where(is.numeric), scale))

```

Re check the random effects model with scaled data:

```{r}
# n_randeffect <- glmer(target_var ~ 
#                         gender + age + I(age^2) + lifesat + religion + class + 
#                         (1|isocntry),
#                data = scaled_df,
#                family = "binomial",
#                control = glmerControl(optimizer = "bobyqa"),
#                nAGQ = 10)

## this took a long time to try run so removed variables. The nAGQ also adds time but fine for now

n_randeffect <- glmer(target_var ~ 
                        gender + age + I(age^2) + lifesat + (1|isocntry),
               data = scaled_df,
               family = "binomial",
               control = glmerControl(optimizer = "bobyqa"),
               nAGQ = 10)



summary(n_randeffect)
```

Can we interpret this...

```{r}

```




*Example Random effects models:* 
m <- glmer(remission ~ IL6 + CRP + CancerStage + LengthofStay + Experience +
    (1 | DID), data = hdp, 
    family = binomial, control = glmerControl(optimizer = "bobyqa"),
    nAGQ = 10)

*Example from last year code*
glm_model_4 <- glmer(binary_qc19 ~ male + d11 + I(d11^2) + political_ideology +
               Religion_cat + sd1_7_factor + d60_ordinal + qc15_1_ordinal +
               prop_gndr_bin + prop_dis_wide + Unemployment + (1 | country_name),
               data = Data, family = binomial, 
               control = glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 100000)))



_Potentially useful package for visualising and interpreting linear mixed models:_ 
Flexplot -> https://github.com/dustinfife/flexplot
Functions to quickly visualise LMM models and compare their performance.

broom.mixed
The function broom.mixed::tidy() gives us all model parameters (random and fixed).



_Useful calculations:_
  - ICC (intra cluster correlation. How alike each of the observations within each group are)
  - ANOVA for model comparison: anova(null_model, lvl1_preds_model, lvl2_preds_model, rs_preds_model)




--------------------------------------------------------------------

think the section below is probably redundant now but just leaving until I check properly. 

--------------------------------------------------------------------

## Remove unwanted variables

The approach above may be best.. but I did start this first by deleting
variables by process of elimination. Maybe good to justify some
decisions, but I'm not sure it matters either way.

-   we do need to decide on some of the attitudinal questions if they
    are relevant enough to include. I haven't looked at all enough in
    detail.

Variable groups I suggest removing: - gen1:gen6 -\> generation
variables, offer no more info than age - nationality variables -\> would
be easier and more accurate to join an overall % of immigration variable
if we want this data. - d71, -\> the three variables are summarised in
the `polintr` variable.

```{r}
id_vars <- c("studyno1", "studyno2", "doi", "version", "edition", "survey", "caseid", "uniqid", "serialid", "tnscntry", "country")
# remove ID vars
clean1 <- data |> 
  select(-any_of(id_vars))

#remove nationality variable (q1). Later, if we decide we need an immigration variable, we can impute national level data.  
clean1 <- clean1 |> 
  select(-any_of(starts_with("q1")))

# remove generation variable, too similar to age
clean1 <- clean1 |> 
  select(-any_of(starts_with("gen")))

# remove additional paradata
# clean1 <- clean1 |> 
#   select(-any_of(starts_with("p7", "p13")))

```

To discuss re: cleaning. But I think also remove all these - qa set
(from qa1 to qa20) \* on trade, globalisation, eu business

-   qb set (from qb1 to qb9) \* on energy policy and EU priorities

Do we delete all these or are we expected to do some sort of
unsupervised learning or similar to consider their attitudes? I think
not.. There is questions about priority for business

Checking how many more variables it removes. It would be 159 removed.

```{r}
data_raw |> 
  select(any_of(starts_with(c("qa", "qb")))) |> 
  ncol()
```

Removing from my test data, this still has 409 variables though.

```{r}
clean1 <- clean1 |> 
  select(-any_of(starts_with(c("qa", "qb"))))

```

## Clean respondents personal data

I think some recoding or factorising may be necessary.

Note: There are lots of haven labelled columns.. it would be quite easy
to write a function to extract the label names to a new column? This
could be easier for when we want to investigate new variables?

```{r}

```

### Impute actual NA values

As these are inconsistent between each variable, I guess we need to
override and decide if we then impute the NA values.

Clean the education variable. Currently we have: d8 - Education, how old
were you when you stopped full time education (Student = 00; No
education = 01; refusal = 98; DK = 99 - d8r1 -\> 11 category recode -
d8r2 -\> 5 category recode

Clean the

```{r}
table(data_raw$d8, data_raw$d8r2)

# First, recode the d8 values that are given as NA or student/no education
clean1 |> 
  mutate(educ = if_else(d8 %in% c(0, 1, 98, 99), NA, d8))

# if d8 = 0, they are a current student. 

```

### Analysis of missing values.

Marga discussed the importance of understanding missing values. I think
this will be an important section where we also model what type of
people are more/less likely to not respond. It's a sort of robustness
check to see how much we can trust the models. Or if specific
demographics of people are less likely to respond, then we may trust it
less.

E.g. if men/religious people are less likely to respond, it could be an
issue. Ideally we would test the representativeness of our respondents
to the questions about transgender discrimination and the overall
populations.

```{r}
#plot_missing()
summary(data_raw$d11)
# returns nothing now because of NA values are all hard coded as mixed values e.g. some are 7, 98, 12. We probably need to standardise, section above maybe
  
```

## Descriptive data analysis and checks to start

Run comparisons by country to compare ages, gender distribution, Number
of respondents per country

```{r}
# number of respondents 
```

## Testing replication of the initial plot:

-   basic version only.

```{r}

```

-   we could also recreate without any NA values to see if it makes the
    plot just seem visually more even to start?

## Modelling

Some initial thoughts:

a)  modelling the target variables
    -   base model -\> using linear mixed model to analyse individual
        and country level differences

    -   model including paradata -\> see if these impacted outcomes too

b\. modelling differences in non-response?

-   I feel like Marga mentioned this? we would need to just create a
    dummy variable for NA response to the target variable question. This
    is our secondary model target variable. I guess this could be a
    classification model? for discussion but also more thoughts in my
    missing data note above...
